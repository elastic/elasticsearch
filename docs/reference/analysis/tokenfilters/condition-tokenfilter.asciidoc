[[analysis-condition-tokenfilter]]
=== Conditional token filter
++++
<titleabbrev>Conditional</titleabbrev>
++++

Applies a set of token filters to tokens that match conditions in a provided
predicate script.

This filter uses Lucene's
{lucene-analysis-docs}/miscellaneous/ConditionalTokenFilter.html[ConditionalTokenFilter].

[[analysis-condition-analyze-ex]]
==== Example

The following <<indices-analyze,analyze API>> request uses the `condition`
filter to match tokens with fewer than 5 characters in `THE QUICK BROWN FOX`.
It then applies the <<analysis-lowercase-tokenfilter,`lowercase`>> filter to
those matching tokens, converting them to lowercase.

[source,console]
--------------------------------------------------
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "condition",
      "filter": [ "lowercase" ],
      "script": {
        "source": "token.getTerm().length() < 5"
      }
    }
  ],
  "text": "THE QUICK BROWN FOX"
}
--------------------------------------------------

The filter produces the following tokens:

[source,text]
--------------------------------------------------
[ the, QUICK, BROWN, fox ]
--------------------------------------------------

/////////////////////
[source,console-result]
--------------------------------------------------
{
  "tokens" : [
    {
      "token" : "the",
      "start_offset" : 0,
      "end_offset" : 3,
      "type" : "<ALPHANUM>",
      "position" : 0
    },
    {
      "token" : "QUICK",
      "start_offset" : 4,
      "end_offset" : 9,
      "type" : "<ALPHANUM>",
      "position" : 1
    },
    {
      "token" : "BROWN",
      "start_offset" : 10,
      "end_offset" : 15,
      "type" : "<ALPHANUM>",
      "position" : 2
    },
    {
      "token" : "fox",
      "start_offset" : 16,
      "end_offset" : 19,
      "type" : "<ALPHANUM>",
      "position" : 3
    }
  ]
}
--------------------------------------------------
/////////////////////

[[analysis-condition-tokenfilter-configure-parms]]
==== Configurable parameters

`filter`::
+
--
(Required, array of token filters)
Array of token filters. If a token matches the predicate script in the `script`
parameter, these filters are applied to the token in the order provided.

These filters can include custom token filters defined in the index mapping.
--

`script`::
+
--
(Required, <<modules-scripting-using,script object>>)
Predicate script used to apply token filters. If a token
matches this script, the filters in the `filter` parameter are applied to the
token.

For valid parameters, see <<modules-scripting-using>>. Only inline scripts are
supported. Painless scripts are executed in the
{painless}/painless-analysis-predicate-context.html[analysis predicate context]
and require a `token` property.
--

[[analysis-condition-tokenfilter-customize]]
==== Customize and add to an analyzer

To customize the `condition` filter, duplicate it to create the basis
for a new custom token filter. You can modify the filter using its configurable
parameters.

For example, the following <<indices-create-index,create index API>> request
uses a custom `condition` filter to configure a new
<<analysis-custom-analyzer,custom analyzer>>. The custom `condition` filter
matches the first token in a stream. It then reverses that matching token using
the <<analysis-reverse-tokenfilter,`reverse`>> filter.

[source,console]
--------------------------------------------------
PUT /palindrome_list
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_reverse_first_token": {
          "tokenizer": "whitespace",
          "filter": [ "reverse_first_token" ]
        }
      },
      "filter": {
        "reverse_first_token": {
          "type": "condition",
          "filter": [ "reverse" ],
          "script": {
            "source": "token.getPosition() === 0"
          }
        }
      }
    }
  }
}
--------------------------------------------------

[[analysis-stemmer-tokenfilter]]
=== Stemmer token filter
++++
<titleabbrev>Stemmer</titleabbrev>
++++

Provides <<algorithmic-stemmers,algorithmic stemming>> for several languages,
some with additional variants. For a list of supported languages, see the
<<analysis-stemmer-tokenfilter-language-parm,`language`>> parameter.

When not customized, the filter uses the
https://snowballstem.org/algorithms/porter/stemmer.html[porter stemming
algorithm] for English.

[[analysis-stemmer-tokenfilter-analyze-ex]]
==== Example

The following analyze API request uses the `stemmer` filter's default porter
stemming algorithm to stem `the foxes jumping quickly` to `the fox jump
quickli`:

[source,console]
----
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [ "stemmer" ],
  "text": "the foxes jumping quickly"
}
----

The filter produces the following tokens:

[source,text]
----
[ the, fox, jump, quickli ]
----

////
[source,console-result]
----
{
  "tokens": [
    {
      "token": "the",
      "start_offset": 0,
      "end_offset": 3,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "fox",
      "start_offset": 4,
      "end_offset": 9,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "jump",
      "start_offset": 10,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "quickli",
      "start_offset": 18,
      "end_offset": 25,
      "type": "<ALPHANUM>",
      "position": 3
    }
  ]
}
----
////

[[analysis-stemmer-tokenfilter-analyzer-ex]]
==== Add to an analyzer

The following <<indices-create-index,create index API>> request uses the
`stemmer` filter to configure a new <<analysis-custom-analyzer,custom
analyzer>>.

[source,console]
----
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "whitespace",
          "filter": [ "stemmer" ]
        }
      }
    }
  }
}
----

[role="child_attributes"]
[[analysis-stemmer-tokenfilter-configure-parms]]
==== Configurable parameters

[[analysis-stemmer-tokenfilter-language-parm]]
`language`::
(Optional, string)
Language-dependent stemming algorithm used to stem tokens. If both this and the
`name` parameter are specified, the `language` parameter argument is used.
+
[%collapsible%open]
.Valid values for `language`
====
Valid values are sorted by language. Defaults to
https://snowballstem.org/algorithms/porter/stemmer.html[*`english`*].
Recommended algorithms are *bolded*.

Arabic::
{lucene-analysis-docs}/ar/ArabicStemmer.html[*`arabic`*]

Armenian::
https://snowballstem.org/algorithms/armenian/stemmer.html[*`armenian`*]

Basque::
https://snowballstem.org/algorithms/basque/stemmer.html[*`basque`*]

Bengali::
https://www.tandfonline.com/doi/abs/10.1080/02564602.1993.11437284[*`bengali`*]

Brazilian Portuguese::
{lucene-analysis-docs}/br/BrazilianStemmer.html[*`brazilian`*]

Bulgarian::
http://members.unine.ch/jacques.savoy/Papers/BUIR.pdf[*`bulgarian`*]

Catalan::
https://snowballstem.org/algorithms/catalan/stemmer.html[*`catalan`*]

Czech::
https://dl.acm.org/doi/10.1016/j.ipm.2009.06.001[*`czech`*]

Danish::
https://snowballstem.org/algorithms/danish/stemmer.html[*`danish`*]

Dutch::
https://snowballstem.org/algorithms/dutch/stemmer.html[*`dutch`*],
https://snowballstem.org/algorithms/kraaij_pohlmann/stemmer.html[`dutch_kp`]

English::
https://snowballstem.org/algorithms/porter/stemmer.html[*`english`*],
https://ciir.cs.umass.edu/pubfiles/ir-35.pdf[`light_english`],
https://snowballstem.org/algorithms/lovins/stemmer.html[`lovins`],
https://www.researchgate.net/publication/220433848_How_effective_is_suffixing[`minimal_english`],
https://snowballstem.org/algorithms/english/stemmer.html[`porter2`],
{lucene-analysis-docs}/en/EnglishPossessiveFilter.html[`possessive_english`]

Estonian::
https://lucene.apache.org/core/{lucene_version_path}/analyzers-common/org/tartarus/snowball/ext/EstonianStemmer.html[*`estonian`*]

Finnish::
https://snowballstem.org/algorithms/finnish/stemmer.html[*`finnish`*],
http://clef.isti.cnr.it/2003/WN_web/22.pdf[`light_finnish`]

French::
https://dl.acm.org/citation.cfm?id=1141523[*`light_french`*],
https://snowballstem.org/algorithms/french/stemmer.html[`french`],
https://dl.acm.org/citation.cfm?id=318984[`minimal_french`]

Galician::
http://bvg.udc.es/recursos_lingua/stemming.jsp[*`galician`*],
http://bvg.udc.es/recursos_lingua/stemming.jsp[`minimal_galician`] (Plural step only)

German::
https://dl.acm.org/citation.cfm?id=1141523[*`light_german`*],
https://snowballstem.org/algorithms/german/stemmer.html[`german`],
https://snowballstem.org/algorithms/german2/stemmer.html[`german2`],
http://members.unine.ch/jacques.savoy/clef/morpho.pdf[`minimal_german`]

Greek::
https://sais.se/mthprize/2007/ntais2007.pdf[*`greek`*]

Hindi::
http://computing.open.ac.uk/Sites/EACLSouthAsia/Papers/p6-Ramanathan.pdf[*`hindi`*]

Hungarian::
https://snowballstem.org/algorithms/hungarian/stemmer.html[*`hungarian`*],
https://dl.acm.org/citation.cfm?id=1141523&dl=ACM&coll=DL&CFID=179095584&CFTOKEN=80067181[`light_hungarian`]

Indonesian::
http://www.illc.uva.nl/Publications/ResearchReports/MoL-2003-02.text.pdf[*`indonesian`*]

Irish::
https://snowballstem.org/otherapps/oregan/[*`irish`*]

Italian::
https://www.ercim.eu/publication/ws-proceedings/CLEF2/savoy.pdf[*`light_italian`*],
https://snowballstem.org/algorithms/italian/stemmer.html[`italian`]

Kurdish (Sorani)::
{lucene-analysis-docs}/ckb/SoraniStemmer.html[*`sorani`*]

Latvian::
{lucene-analysis-docs}/lv/LatvianStemmer.html[*`latvian`*]

Lithuanian::
https://svn.apache.org/viewvc/lucene/dev/branches/lucene_solr_5_3/lucene/analysis/common/src/java/org/apache/lucene/analysis/lt/stem_ISO_8859_1.sbl?view=markup[*`lithuanian`*]

Norwegian (Bokm√•l)::
https://snowballstem.org/algorithms/norwegian/stemmer.html[*`norwegian`*],
{lucene-analysis-docs}/no/NorwegianLightStemmer.html[*`light_norwegian`*],
{lucene-analysis-docs}/no/NorwegianMinimalStemmer.html[`minimal_norwegian`]

Norwegian (Nynorsk)::
{lucene-analysis-docs}/no/NorwegianLightStemmer.html[*`light_nynorsk`*],
{lucene-analysis-docs}/no/NorwegianMinimalStemmer.html[`minimal_nynorsk`]

Persian::
{lucene-analysis-docs}/fa/PersianStemmer.html[*`persian`*]

Portuguese::
https://dl.acm.org/citation.cfm?id=1141523&dl=ACM&coll=DL&CFID=179095584&CFTOKEN=80067181[*`light_portuguese`*],
pass:macros[http://www.inf.ufrgs.br/~buriol/papers/Orengo_CLEF07.pdf[`minimal_portuguese`\]],
https://snowballstem.org/algorithms/portuguese/stemmer.html[`portuguese`],
https://www.inf.ufrgs.br/\~viviane/rslp/index.htm[`portuguese_rslp`]

Romanian::
https://snowballstem.org/algorithms/romanian/stemmer.html[*`romanian`*]

Russian::
https://snowballstem.org/algorithms/russian/stemmer.html[*`russian`*],
https://doc.rero.ch/lm.php?url=1000%2C43%2C4%2C20091209094227-CA%2FDolamic_Ljiljana_-_Indexing_and_Searching_Strategies_for_the_Russian_20091209.pdf[`light_russian`]

Serbian::
https://snowballstem.org/algorithms/serbian/stemmer.html[*`serbian`*]

Spanish::
https://www.ercim.eu/publication/ws-proceedings/CLEF2/savoy.pdf[*`light_spanish`*],
https://snowballstem.org/algorithms/spanish/stemmer.html[`spanish`]
https://www.wikilengua.org/index.php/Plural_(formaci%C3%B3n)[`spanish_plural`]

Swedish::
https://snowballstem.org/algorithms/swedish/stemmer.html[*`swedish`*],
http://clef.isti.cnr.it/2003/WN_web/22.pdf[`light_swedish`]

Turkish::
https://snowballstem.org/algorithms/turkish/stemmer.html[*`turkish`*]
====

`name`::
An alias for the <<analysis-stemmer-tokenfilter-language-parm,`language`>>
parameter. If both this and the `language` parameter are specified, the
`language` parameter argument is used.

[[analysis-stemmer-tokenfilter-customize]]
==== Customize

To customize the `stemmer` filter, duplicate it to create the basis for a new
custom token filter. You can modify the filter using its configurable
parameters.

For example, the following request creates a custom `stemmer` filter that stems
words using the `light_german` algorithm:

[source,console]
----
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_stemmer"
          ]
        }
      },
      "filter": {
        "my_stemmer": {
          "type": "stemmer",
          "language": "light_german"
        }
      }
    }
  }
}
----

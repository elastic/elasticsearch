[[analysis-synonym-tokenfilter]]
=== Synonym token filter
++++
<titleabbrev>Synonym</titleabbrev>
++++

The `synonym` token filter allows to easily handle <<search-with-synonyms,synonyms>> during the
analysis process.

[discrete]
[[analysis-synonym-define-synonyms]]
==== Define synonyms sets

include::synonyms-format.asciidoc[]

[discrete]
[[analysis-synonym-configure-sets]]
==== Configure synonyms sets

Synonyms can be configured using the <<synonyms-store-synonyms-api,synonyms API>>, a <<synonyms-store-synonyms-file,synonyms file>>, or directly <<synonyms-store-synonyms-inline,inlined>> in the token filter configuration.
See <<synonyms-store-synonyms,store your synonyms set>> for more details on each option.

Use `synonyms_set` configuration option to provide a synonym set created via Synonyms Management APIs:

[source,JSON]
----
  "filter": {
    "synonyms_filter": {
      "type": "synonym",
      "synonyms_set": "my-synonym-set",
      "updateable": true
    }
  }
----

Use `synonyms_path` to provide a synonym file :

[source,JSON]
----
  "filter": {
    "synonyms_filter": {
      "type": "synonym",
      "synonyms_path": "analysis/synonym-set.txt"
    }
  }
----

The above configures a `synonym` filter, with a path of
`analysis/synonym-set.txt` (relative to the `config` location).

Use `synonyms` to define inline synonyms:

[source,JSON]
----
  "filter": {
    "synonyms_filter": {
      "type": "synonym",
      "synonyms": ["pc => personal computer", "computer, pc, laptop"]
    }
  }
----

Additional settings are:

* `updateable` (defaults to `false`). If `true` allows
<<indices-reload-analyzers,reloading>> search analyzers to pick up
changes to synonym files. Only to be used for search analyzers.
* `expand` (defaults to `true`).
* `lenient` (defaults to `false`). If `true` ignores exceptions while parsing the synonym configuration. It is important
to note that only those synonym rules which cannot get parsed are ignored. For instance consider the following request:


[source,console]
--------------------------------------------------
PUT /test_index
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "synonym": {
            "tokenizer": "standard",
            "filter": [ "my_stop", "synonym" ]
          }
        },
        "filter": {
          "my_stop": {
            "type": "stop",
            "stopwords": [ "bar" ]
          },
          "synonym": {
            "type": "synonym",
            "lenient": true,
            "synonyms": [ "foo, bar => baz" ]
          }
        }
      }
    }
  }
}
--------------------------------------------------

With the above request the word `bar` gets skipped but a mapping `foo => baz` is still added. However, if the mapping
being added was `foo, baz => bar` nothing would get added to the synonym list. This is because the target word for the
mapping is itself eliminated because it was a stop word. Similarly, if the mapping was "bar, foo, baz" and `expand` was
set to `false` no mapping would get added as when `expand=false` the target mapping is the first word. However, if
`expand=true` then the mappings added would be equivalent to `foo, baz => foo, baz` i.e, all mappings other than the
stop word.


[discrete]
[[synonym-tokenizer-ignore_case-deprecated]]
===== `tokenizer` and `ignore_case` are deprecated

The `tokenizer` parameter controls the tokenizers that will be used to
tokenize the synonym, this parameter is for backwards compatibility for indices that created before 6.0.
The `ignore_case` parameter works with `tokenizer` parameter only.

[discrete]
[[analysis-synonym-analizers-configure]]
==== Configure analyzers with synonym token filters

To apply synonyms, you will need to include a synonym token filters into an analyzer:

[source,JSON]
----
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["stemmer", "synonym_graph"]
        }
      }
----

[discrete]
[[analysis-synonym-token-order]]
===== Token filters ordering

Order is important for your token filters.
Text will be processed first through filters preceding the synonym filter before being processed by the synonym filter.

{es} will also use the token filters preceding the synonym filter in a tokenizer chain to parse the entries in a synonym file or synonym set.
In the above example, the synonyms graph token filter is placed after a stemmer. The stemmer will also be applied to the synonym entries.

The synonym rules should not contain words that are removed by a filter that appears later in the chain (like a `stop` filter).
Removing a term from a synonym rule means there will be no matching for it at query time.

Because entries in the synonym map cannot have stacked positions, some token filters may cause issues here.
Token filters that produce multiple versions of a token may choose which version of the token to emit when parsing synonyms.
For example, `asciifolding` will only produce the folded version of the token.
Others, like `multiplexer`, `word_delimiter_graph` or `ngram` will throw an error.

If you need to build analyzers that include both multi-token filters and synonym filters, consider using the <<analysis-multiplexer-tokenfilter,multiplexer>> filter, with the multi-token filters in one branch and the synonym filter in the other.

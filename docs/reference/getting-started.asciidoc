[chapter]
[[getting-started]]
= Quick start

This guide helps beginners learn how to:

* Install and run {es} in a test environment (Using {ecloud} or Docker)
* Add (non-timestamped) data to {es}
* Search and sort data
* Aggregate data

[TIP]
====
If you're interested in using {es} with Python, check out Elastic Search Labs:

* https://www.elastic.co/search-labs/tutorials/search-tutorial/welcome[Tutorial]. This extensive, hands-on tutorial walks you through building a complete search solution with {es}, from the ground up.
* https://github.com/elastic/elasticsearch-labs[`elasticsearch-labs`]. This Github repository contains a range of executable Python https://github.com/elastic/elasticsearch-labs/tree/main/notebooks[notebooks] and https://github.com/elastic/elasticsearch-labs/tree/main/example-apps[example apps].
====

[discrete]
[[run-elasticsearch]]
=== Run {es}

The simplest way to set up {es} is to create a managed deployment with {ess} on
{ecloud}. If you prefer to manage your own test environment, you can install and
run {es} using Docker.

include::{es-repo-dir}/tab-widgets/code.asciidoc[]
include::{es-repo-dir}/tab-widgets/quick-start-install-widget.asciidoc[]

[discrete]
[[send-requests-to-elasticsearch]]
=== Send requests to {es}

You send data and other requests to {es} using REST APIs. This lets you interact
with {es} using any client that sends HTTP requests, such as
https://curl.se[curl]. You can also use {kib}'s Console to send requests to
{es}.

include::{es-repo-dir}/tab-widgets/api-call-widget.asciidoc[]

[discrete]
[[add-data]]
=== Add data

You add data to {es} as JSON objects called documents. {es} stores these
documents in searchable indices.

[discrete]
[[add-single-document]]
==== Add a single document

Submit the following indexing request to add a single document to the
`books` index.
Since `index` doesn't exist yet, the
request automatically creates it.

[source,console]
----
POST books/_doc
{"name": "Snow Crash", "author": "Neal Stephenson", "release_date": "1992-06-01", "page_count": 470}
----
// TEST[skip:for now]
// TEST[s/_doc/_doc?refresh=wait_for/]

The response includes metadata that {es} generates for the document including a unique `_id` for the document within the index.

[source,console-result]
----
{
  "_index": "books",
  "_id": "O0lG2IsBaSa7VYx_rEia",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 2,
    "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}
----
// TESTRESPONSE[skip:for now]
// TESTRESPONSE[s/"_index": "books"/"_index": $body._index/]
// TESTRESPONSE[s/"_id": "O0lG2IsBaSa7VYx_rEia"/"_id": $body._id/]
// TESTRESPONSE[s/"result": "created"/"result": $body.result/]

[discrete]
[[add-multiple-documents]]
==== Add multiple documents

Use the `_bulk` endpoint to add multiple documents in one request. Bulk data
must be newline-delimited JSON (NDJSON). Each line must end in a newline
character (`\n`), including the last line.

[source,console]
----
POST /_bulk
{ "index" : { "_index" : "books" } }
{"name": "Revelation Space", "author": "Alastair Reynolds", "release_date": "2000-03-15", "page_count": 585}
{ "index" : { "_index" : "books" } }
{"name": "1984", "author": "George Orwell", "release_date": "1985-06-01", "page_count": 328}
{ "index" : { "_index" : "books" } }
{"name": "Fahrenheit 451", "author": "Ray Bradbury", "release_date": "1953-10-15", "page_count": 227}
{ "index" : { "_index" : "books" } }
{"name": "Brave New World", "author": "Aldous Huxley", "release_date": "1932-06-01", "page_count": 268}
{ "index" : { "_index" : "books" } }
{"name": "The Handmaids Tale", "author": "Margaret Atwood", "release_date": "1985-06-01", "page_count": 311}
----
// TEST[skip:for now]
// TEST[continued]
// TEST[s/_bulk/_bulk?refresh=wait_for/]

You should receive a response indicating there were no errors:

[source,console-result]
----
{
  "errors": false,
  "took": 29,
  "items": [
    {
      "index": {
        "_index": "books",
        "_id": "QklI2IsBaSa7VYx_Qkh-",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 2,
          "failed": 0
        },
        "_seq_no": 1,
        "_primary_term": 1,
        "status": 201
      }
    },
    {
      "index": {
        "_index": "books",
        "_id": "Q0lI2IsBaSa7VYx_Qkh-",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 2,
          "failed": 0
        },
        "_seq_no": 2,
        "_primary_term": 1,
        "status": 201
      }
    },
    {
      "index": {
        "_index": "books",
        "_id": "RElI2IsBaSa7VYx_Qkh-",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 2,
          "failed": 0
        },
        "_seq_no": 3,
        "_primary_term": 1,
        "status": 201
      }
    },
    {
      "index": {
        "_index": "books",
        "_id": "RUlI2IsBaSa7VYx_Qkh-",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 2,
          "failed": 0
        },
        "_seq_no": 4,
        "_primary_term": 1,
        "status": 201
      }
    },
    {
      "index": {
        "_index": "books",
        "_id": "RklI2IsBaSa7VYx_Qkh-",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 2,
          "failed": 0
        },
        "_seq_no": 5,
        "_primary_term": 1,
        "status": 201
      }
    }
  ]
}
----
// TESTRESPONSE[skip:for now]
// TESTRESPONSE[s/"took": 189/"took": $body.took/]
// TESTRESPONSE[s/"_index": "books"/"_index": $body.items.0.index._index/]
// TESTRESPONSE[s/"_id": "IEkx2IsBaSa7VYx_vkj6"/"_id": $body.items.0.index._id/]
// TESTRESPONSE[s/"_index": "books"/"_index": $body.items.1.index._index/]

[discrete]
[[qs-search-data]]
=== Search data

Indexed documents are available for search in near real-time.
Run the following command to search the `books` index for documents containing `snow`:

[source,console]
----
GET books/_search
{
  "query": {
    "query_string": {
      "query": "snow"
    }
  }
}
----
// TEST[skip:for now]
// TEST[continued]

By default, the `hits` section of the response includes up to the first 10
documents that match the search.
The `_source` of each hit contains the original
JSON object submitted during indexing.

[source,console-result]
----
{
  "took": 14,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1.5904956,
    "hits": [
      {
        "_index": "books",
        "_id": "IEkx2IsBaSa7VYx_vkj6",
        "_score": 1.5904956,
        "_source": {
          "name": "Snow Crash",
          "author": "Neal Stephenson",
          "release_date": "1992-06-01",
          "page_count": 470
        }
      }
    ]
  }
}
----
//TESTRESPONSE[skip:for now]
// TESTRESPONSE[s/"took": 2/"took": $body.took/]
// TESTRESPONSE[s/"_index": ".ds-logs-my_app-default-2099-05-06-000001"/"_index": $body.hits.hits.0._index/]
// TESTRESPONSE[s/"_id": "PdjWongB9KPnaVm2IyaL"/"_id": $body.hits.hits.0._id/]
// TESTRESPONSE[s/\.\.\./$body.hits.hits.1,$body.hits.hits.2/]

[discrete]
[[get-specific-fields]]
==== Get specific fields

Parsing the entire `_source` is unwieldy for large documents. To exclude it from
the response, set the `_source` parameter to `false`. Instead, use the `fields`
parameter to retrieve the fields you want.
Here's an example that returns only the `author` field.

[source,console]
----
GET books/_search
{
  "query": {
    "match_all": { }
  },
  "fields": [
    "author"
  ],
  "_source": false
}
----
// TEST[SKIP:for now]
// TEST[continued]
// TEST[s/_search/_search?filter_path=hits.hits&size=1/]

The response contains each hit's `fields` values as a flat array.

[source,console-result]
----
{
  "took": 5,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 6,
      "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "books",
        "_id": "O0lG2IsBaSa7VYx_rEia",
        "_score": 1,
        "fields": {
          "author": [
            "Neal Stephenson"
          ]
        }
      },
      {
        "_index": "books",
        "_id": "QklI2IsBaSa7VYx_Qkh-",
        "_score": 1,
        "fields": {
          "author": [
            "Alastair Reynolds"
          ]
        }
      },
      {
        "_index": "books",
        "_id": "Q0lI2IsBaSa7VYx_Qkh-",
        "_score": 1,
        "fields": {
          "author": [
            "George Orwell"
          ]
        }
      },
      {
        "_index": "books",
        "_id": "RElI2IsBaSa7VYx_Qkh-",
        "_score": 1,
        "fields": {
          "author": [
            "Ray Bradbury"
          ]
        }
      },
      {
        "_index": "books",
        "_id": "RUlI2IsBaSa7VYx_Qkh-",
        "_score": 1,
        "fields": {
          "author": [
            "Aldous Huxley"
          ]
        }
      },
      {
        "_index": "books",
        "_id": "RklI2IsBaSa7VYx_Qkh-",
        "_score": 1,
        "fields": {
          "author": [
            "Margaret Atwood"
          ]
        }
      }
    ]
  }
}
----
// TESTRESPONSE[SKIP:for now]
// TESTRESPONSE[s/\.\.\.//]
// TESTRESPONSE[s/"_index": ".ds-logs-my_app-default-2099-05-06-000001"/"_index": $body.hits.hits.0._index/]
// TESTRESPONSE[s/"_id": "PdjWongB9KPnaVm2IyaL"/"_id": $body.hits.hits.0._id/]
// TESTRESPONSE[s/4081940742000\n        \]\n      \},\n/4081940742000\]}/]

[discrete]
[[combine-queries]]
==== Combine queries

You can use the `bool` query to combine multiple queries.
Let's imagine a scenario where you want to find books based on multiple criteria: author and page count.
This requires a combination of a `terms` query (for the authors) and a `range` query (for the page count).

[source,console]
----
GET /books/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "terms": {
            "author.keyword": ["Neal Stephenson", "Ray Bradbury"]
          }
        },
        {
          "range": {
            "page_count": {
              "gte": 200,
              "lte": 300
            }
          }
        }
      ]
    }
  }
}
----
// TEST[skip:for now]
// TEST[continued]

The response contains the books that match the query.

[source,console-result]
----
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 2,
    "hits": [
      {
        "_index": "books",
        "_id": "I0kx2IsBaSa7VYx_vkj6",
        "_score": 2,
        "_source": {
          "name": "Fahrenheit 451",
          "author": "Ray Bradbury",
          "release_date": "1953-10-15",
          "page_count": 227
        }
      }
    ]
  }
}
----
// TESTRESPONSE[SKIP:for now]
// TESTRESPONSE[s/"took": 1/"took": $body.took/]
// TESTRESPONSE[s/"_index": "books"/"_index": $body.hits.hits.0._index/]
// TESTRESPONSE[s/"_id": "I0kx2IsBaSa7VYx_vkj6"/"_id": $body.hits.hits.0._id/]
// TESTRESPONSE[s/\.\.\./$body.hits.hits.1,$body.hits.hits.2/]

[discrete]
[[aggregate-data]]
==== Aggregate data

Use aggregations to summarize data as metrics, statistics, or other analytics.
Let's say we want to calculate the average page count for each author.

The following search uses an `aggs` clause to calculate the average page count:

[source,console]
----
GET /books/_search
{
  "size": 0,  // This omits the actual search results and only returns the aggregations
  "aggs": {
    "average_pages_by_author": {
      "terms": {
        "field": "author.keyword",
        "size": 10  // Adjust this to get more or fewer authors
      },
      "aggs": {
        "average_page_count": {
          "avg": {
            "field": "page_count"
          }
        }
      }
    }
  }
}
----
// TEST[skip:for now]
// TEST[continued]

The responseâ€™s `aggregations` object contains aggregation results.

[source,console-result]
----
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 6,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "average_pages_by_author": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "Alastair Reynolds",
          "doc_count": 1,
          "average_page_count": {
            "value": 585
          }
        },
        {
          "key": "Aldous Huxley",
          "doc_count": 1,
          "average_page_count": {
            "value": 268
          }
        },
        {
          "key": "George Orwell",
          "doc_count": 1,
          "average_page_count": {
            "value": 328
          }
        },
        {
          "key": "Margaret Atwood",
          "doc_count": 1,
          "average_page_count": {
            "value": 311
          }
        },
        {
          "key": "Neal Stephenson",
          "doc_count": 1,
          "average_page_count": {
            "value": 470
          }
        },
        {
          "key": "Ray Bradbury",
          "doc_count": 1,
          "average_page_count": {
            "value": 227
          }
        }
      ]
    }
  }
}
----
// TESTRESPONSE[SKIP:for now]

[discrete]
[[whats-next]]
=== Next steps

Now that {es} is up and running and you've learned the basics, you'll probably want to test out larger datasets, or index your own data.

Here are a few relevant links:

[discrete]
[[whats-next-sample-data]]
==== Try sample data

* Learn how to {kibana-ref}/sample-data.html[install sample data] using {kib}. This is a quick way to test out {es} on larger workloads.
** Check out the https://github.com/elastic/kibana/tree/main/src/plugins/home/server/services/sample_data/data_sets[the raw sample data] in the {kib} repo, if you'd like to work with the data programmatically.

[discrete]
[[whats-next-upload-data]]
==== Upload your own data

* Learn how to use the {kibana-ref}/connect-to-elasticsearch.html#upload-data-kibana[upload data UI] in {kib} to add your own CSV, TSV, or JSON files.
* Use the https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html[bulk API] to ingest your own datasets to {es}.
** If you'd like to use Python, check out https://www.elastic.co/search-labs/tutorials/search-tutorial/full-text-search/create-index#ingesting-documents-from-a-json-file[ingesting documents from a JSON file] in the Elastic Search Labs tutorial.

[discrete]
[[whats-next-client-libraries]]
==== Integrate with your own application

* To integrate {es} with your own application, you'll want to use a https://www.elastic.co/guide/en/elasticsearch/client/index.html[client library] for your preferred language.
** If you're using Python, check out https://www.elastic.co/search-labs[Elastic Search Labs] for a range of examples that use the {es} Python client.

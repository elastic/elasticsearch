[[aggregations-tutorial]]
== Analyze eCommerce data with aggregations using Query DSL
++++
<titleabbrev>Basics: Analyze eCommerce data with aggregations</titleabbrev>
++++

This hands-on tutorial shows you how to analyze eCommerce data using {es} <<search-aggregations,aggregations>> with the `_search` API and Query DSL.

You'll learn how to:

* Calculate key business metrics such as average order value
* Analyze sales patterns over time
* Compare performance across product categories 
* Track moving averages and cumulative totals

[discrete]
[[aggregations-tutorial-requirements]]
=== Requirements

You'll need:

* A <<elasticsearch-intro-deploy,running {es} cluster>>, together with {kib} to use the Dev Tools API Console.
** If you don't already have a cluster, run the following command in your terminal to set up a <<run-elasticsearch-locally,local dev environment>>:
+
[source,sh]
----
curl -fsSL https://elastic.co/start-local | sh
----
// NOTCONSOLE
* To load the {kibana-ref}/get-started.html#gs-get-data-into-kibana[Kibana sample eCommerce data].

[discrete]
[[aggregations-tutorial-basic-metrics]]
=== Get key business metrics

Let's start by calculating important metrics about orders and customers.

[discrete]
[[aggregations-tutorial-order-value]]
==== Get average order size

Calculate the average order value across all orders in the dataset using the <<search-aggregations-metrics-avg-aggregation,`avg`>> aggregation.

[source,console]
----
GET kibana_sample_data_ecommerce/_search
{
 "size": 0, <1>
 "aggs": {
   "avg_order_value": { <2>
     "avg": { <3>
       "field": "taxful_total_price"
     }
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> Set `size` to 0 to avoid returning matched documents in the response and return only the aggregation results
<2> A meaningful name that describes what this metric represents
<3> Configures an `avg` aggregation, which calculates a simple arithmetic mean

.Example response
[%collapsible]
====
[source,console-result]
----
{
  "took": 0,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 4675, <1>
      "relation": "eq"
    },
    "max_score": null,
    "hits": [] <2>
  },
  "aggregations": {
    "avg_order_value": { <3>
      "value": 75.05542864304813 <4>
    }
  }
}
----
// TEST[skip:Using Kibana sample data]
<1> Total number of orders in the dataset
<2> `hits` is empty because we set `size` to 0
<3> Results appear under the name we specified in the request
<4> The average order value is calculated dynamically from all the orders in the dataset
====

[discrete]
[[aggregations-tutorial-order-stats]]
==== Get multiple order statistics at once

Calculate multiple statistics about orders in one request using the <<search-aggregations-metrics-stats-aggregation,`stats`>> aggregation.

[source,console]
----
GET kibana_sample_data_ecommerce/_search
{
 "size": 0,
 "aggs": {
   "order_stats": { <1>
     "stats": { <2>
       "field": "taxful_total_price"
     }
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> A descriptive name for this set of statistics
<2> `stats` returns count, min, max, avg, and sum at once

.Example response
[%collapsible]
====
[source,console-result]
----
{
 "aggregations": {
   "order_stats": {
     "count": 4675, <1>
     "min": 6.98828125, <2>
     "max": 2250, <3>
     "avg": 75.05542864304813, <4>
     "sum": 350884.12890625 <5>
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> `"count"`: Total number of orders in the dataset
<2> `"min"`: Lowest individual order value in the dataset
<3> `"max"`: Highest individual order value in the dataset
<4> `"avg"`: Average value per order across all orders
<5> `"sum"`: Total revenue from all orders combined
====

[TIP]
====
The <<search-aggregations-metrics-stats-aggregation,stats aggregation>> is more efficient than running individual min, max, avg, and sum aggregations.
====

[discrete]
[[aggregations-tutorial-sales-patterns]]
=== Analyze sales patterns

Let's group orders in different ways to understand sales patterns.

[discrete]
[[aggregations-tutorial-category-breakdown]]
==== Break down sales by category

Group orders by category to see which product categories are most popular, using the <<search-aggregations-bucket-terms-aggregation,`terms`>> aggregation.

[source,console]
----
GET kibana_sample_data_ecommerce/_search
{
 "size": 0,
 "aggs": {
   "sales_by_category": { <1>
     "terms": { <2>
       "field": "category.keyword", <3>
       "size": 5, <4>
       "order": { "_count": "desc" } <5>
     }
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> Name reflecting the business purpose of this breakdown
<2> `terms` aggregation groups documents by field values
<3> Use <<keyword,`.keyword`>> field for exact matching on text fields
<4> Limit to top 5 categories 
<5> Order by number of orders (descending)

.Example response
[%collapsible]
====
[source,console-result]
----
...
 "aggregations": {
    "sales_by_category": {
      "doc_count_error_upper_bound": 0, <1>
      "sum_other_doc_count": 572, <2>
      "buckets": [ <3>
        {
          "key": "Men's Clothing", <4>
          "doc_count": 2024 <5>
        },
        {
          "key": "Women's Clothing",
          "doc_count": 1903
        },
        {
          "key": "Women's Shoes",
          "doc_count": 1136
        },
        {
          "key": "Men's Shoes",
          "doc_count": 944
        },
        {
          "key": "Women's Accessories",
          "doc_count": 830
        }
      ]
    }
 }
----
// TEST[skip:Using Kibana sample data]
<1> Due to Elasticsearch's distributed architecture, when <<search-aggregations-bucket-terms-aggregation,terms aggregations>> run across multiple shards, the doc counts may have a small margin of error. This value indicates the maximum possible error in the counts.
<2> Count of documents in categories beyond the requested size.
<3> Array of category buckets, ordered by count.
<4> Category name.
<5> Number of orders in this category.
====

[discrete]
[[aggregations-tutorial-daily-sales]]
==== Track daily sales patterns

Group orders by day to track daily sales patterns using the <<search-aggregations-bucket-datehistogram-aggregation,`date_histogram`>> aggregation.

[source,console]
----
GET kibana_sample_data_ecommerce/_search
{
 "size": 0,
 "aggs": {
   "daily_orders": { <1>
     "date_histogram": { <2>
       "field": "order_date",
       "calendar_interval": "day", <3>
       "format": "yyyy-MM-dd", <4>
       "min_doc_count": 0 <5>
     }
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> Descriptive name for the time-series aggregation results.
<2> The `date_histogram` aggregration groups documents into time-based buckets, similar to terms aggregation but for dates.
<3> Uses <<calendar_and_fixed_intervals,calendar and fixed time intervals>> to handle months with different lengths. `"day"` ensures consistent daily grouping regardless of timezone.
<4> Formats dates in response using <<mapping-date-format,date patterns>> (e.g. "yyyy-MM-dd"). Refer to <<date-math,date math expressions>> for additional options.
<5> When `min_doc_count` is 0, returns buckets for days with no orders, useful for continuous time series visualization.

[discrete]
[[aggregations-tutorial-combined-analysis]]
=== Combine metrics with groupings

Now let's calculate <<search-aggregations-metrics,metrics>> within each group to get deeper insights.

[discrete]
[[aggregations-tutorial-category-metrics]]
==== Compare category performance

Calculate metrics within each category to compare performance across categories.

[source,console]
----
GET kibana_sample_data_ecommerce/_search
{
 "size": 0,
 "aggs": {
   "categories": {
     "terms": {
       "field": "category.keyword",
       "size": 5,
       "order": { "total_revenue": "desc" } <1>
     },
     "aggs": { <2>
       "total_revenue": { <3>
         "sum": {
           "field": "taxful_total_price"
         }
       },
       "avg_order_value": { <4>
         "avg": {
           "field": "taxful_total_price"
         }
       },
       "total_items": { <5>
         "sum": {
           "field": "total_quantity"
         }
       }
     }
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> Order categories by their total revenue instead of count
<2> Define metrics to calculate within each category
<3> Total revenue for the category
<4> Average order value in the category
<5> Total number of items sold

.Example response
[%collapsible]
====
[source,console-result]
----
{
 "aggregations": {
   "categories": {
     "buckets": [
       {
         "key": "Men's Clothing", <1>
         "doc_count": 2179, <2>
         "total_revenue": { <3>
           "value": 156729.453125
         },
         "avg_order_value": { <4>
           "value": 71.92726898715927
         },
         "total_items": { <5>
           "value": 8716
         }
       },
       {
         "key": "Women's Clothing",
         "doc_count": 2262,
         ...
       }
     ]
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> Category name
<2> Number of orders
<3> Total revenue for this category
<4> Average order value for this category
<5> Total quantity of items sold
====

[discrete]
[[aggregations-tutorial-daily-metrics]]
==== Analyze daily sales performance

Let's combine metrics to track daily trends: daily revenue, unique customers, and average basket size.

[source,console]
----
GET kibana_sample_data_ecommerce/_search
{
 "size": 0,
 "aggs": {
   "daily_sales": {
     "date_histogram": {
       "field": "order_date",
       "calendar_interval": "day",
       "format": "yyyy-MM-dd"
     },
     "aggs": {
       "revenue": { <1>
         "sum": {
           "field": "taxful_total_price"
         }
       },
       "unique_customers": { <2>
         "cardinality": {
           "field": "customer_id"
         }
       },
       "avg_basket_size": { <3>
         "avg": {
           "field": "total_quantity"
         }
       }
     }
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> Daily revenue
<2> Uses the <<search-aggregations-metrics-cardinality-aggregation,`cardinality`>> aggregation to count unique customers per day
<3> Average number of items per order

[discrete]
[[aggregations-tutorial-trends]]
=== Track trends and patterns

You can use <<search-aggregations-pipeline,pipeline aggregations>> on the results of other aggregations.
Let's analyze how metrics change over time.

[discrete]
[[aggregations-tutorial-moving-average]]
==== Smooth out daily fluctuations

Moving averages help identify trends by reducing day-to-day noise in the data.
Let's observe sales trends more clearly by smoothing daily revenue variations, using the <<search-aggregations-pipeline-movfn-aggregation,Moving Function>> aggregation.

[source,console]
----
GET kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "daily_sales": {
      "date_histogram": {
        "field": "order_date",
        "calendar_interval": "day"
      },
      "aggs": {
        "daily_revenue": {  <1>
          "sum": {
            "field": "taxful_total_price"
          }
        },
        "smoothed_revenue": { <2>
          "moving_fn": { <3>
            "buckets_path": "daily_revenue", <4>
            "window": 3, <5>
            "script": "MovingFunctions.unweightedAvg(values)" <6>
          }
        }
      }
    }
  }
}
----
// TEST[skip:Using Kibana sample data]
<1> Calculate daily revenue first.
<2> Create a smoothed version of the daily revenue.
<3> Use `moving_fn` for moving window calculations.
<4> Reference the revenue from our date histogram.
<5> Use a 3-day window â€” use different window sizes to see trends at different time scales.
<6> Use the built-in unweighted average function in the `moving_fn` aggregation.

.Example response (truncated)
[%collapsible]
====
[source,console-result]
----
{ ...
  "aggregations": {
    "daily_sales": {
      "buckets": [
        {
          "key_as_string": "2024-10-24T00:00:00.000Z", <1>
          "key": 1729728000000,
          "doc_count": 146, <2>
          "daily_revenue": {
            "value": 10578.53125 <3>
          },
          "smoothed_revenue": {
            "value": null <4>
          }
        },
        {
          "key_as_string": "2024-10-25T00:00:00.000Z",
          "key": 1729814400000,
          "doc_count": 153,
          "daily_revenue": {
            "value": 10448
          },
          "smoothed_revenue": {
            "value": 10578.53125 <5>
          }
        },
        ...
----
// TEST[skip:Using Kibana sample data]
<1> Date of the bucket is in default ISO format because we didn't specify a format
<2> Number of orders for this day
<3> Raw daily revenue before smoothing
<4> First day has no smoothed value as it needs previous days for the calculation
<5> Moving average starts from second day, using a 3-day window
====

[TIP]
====
Notice how the smoothed values lag behind the actual values - this is because they need previous days' data to calculate. The first day will always be null when using moving averages.
====

[discrete]
[[aggregations-tutorial-cumulative]]
==== Track running totals

Track running totals over time using the <<search-aggregations-pipeline-cumulative-sum-aggregation,`cumulative_sum`>> aggregation.

[source,console]
----
GET kibana_sample_data_ecommerce/_search
{
 "size": 0,
 "aggs": {
   "daily_sales": {
     "date_histogram": {
       "field": "order_date",
       "calendar_interval": "day"
     },
     "aggs": {
       "revenue": {
         "sum": {
           "field": "taxful_total_price"
         }
       },
       "cumulative_revenue": { <1>
         "cumulative_sum": { <2>
           "buckets_path": "revenue" <3>
         }
       }
     }
   }
 }
}
----
// TEST[skip:Using Kibana sample data]
<1> Name for our running total
<2> `cumulative_sum` adds up values across buckets
<3> Reference the revenue we want to accumulate

[discrete]
[[aggregations-tutorial-next-steps]]
=== Next steps

Refer to the <<search-aggregations,aggregations reference>> for more details on all available aggregation types.

//TODO add relevant links judiciously
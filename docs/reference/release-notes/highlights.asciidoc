[[release-highlights]]
== What's new in {minor-version}

coming[{minor-version}]

Here are the highlights of what's new and improved in {es} {minor-version}!
ifeval::["{release-state}"!="unreleased"]
For detailed information about this release, see the
<<release-notes-{elasticsearch_version}, Release notes >> and
<<breaking-changes-{minor-version}, Breaking changes>>.
endif::[]

// Add previous release to the list
Other versions:
{ref-bare}/7.8/release-highlights.html[7.8]
| {ref-bare}/7.7/release-highlights.html[7.7]
| {ref-bare}/7.6/release-highlights-7.6.0.html[7.6]
| {ref-bare}/7.5/release-highlights-7.5.0.html[7.5]
| {ref-bare}/7.4/release-highlights-7.4.0.html[7.4]
| {ref-bare}/7.3/release-highlights-7.3.0.html[7.3]
| {ref-bare}/7.2/release-highlights-7.2.0.html[7.2]
| {ref-bare}/7.1/release-highlights-7.1.0.html[7.1]
| {ref-bare}/7.0/release-highlights-7.0.0.html[7.0]



// Use the notable-highlights tag to mark entries that
// should be featured in the Stack Installation and Upgrade Guide:
// tag::notable-highlights[]
// [discrete]
// === Heading
//
// Description.
// end::notable-highlights[]

// Omit the notable highlights tag for entries that only need to appear in the ES ref:
// [float]
// === Heading
//
// Description.

// tag::notable-highlights[]
[discrete]
=== EQL

EQL (Event Query Language) is a declarative language dedicated for identifying patterns and relationships between events.

Consider using EQL if you:

* Use {es} for threat hunting or other security use cases
* Search time series data or logs, such as network or system logs
* Want an easy way to explore relationships between events

A good intro on EQL and its purpose is available
https://www.elastic.co/blog/introducing-event-query-language[in this blog
post]. See the <<eql,EQL in Elasticsearch>> documentaton for an in-depth
explanation, and also the
https://eql.readthedocs.io/en/latest/query-guide/index.html[language
reference].

This release includes the following features:

* Event queries
* Sequences
* Pipes

An in-depth discussion of EQL in ES scope can be found at {es-issue}49581[#49581].
// end::notable-highlights[]

// tag::notable-highlights[]
[discrete]
=== Data streams

A _data stream_ is a convenient, scalable way to ingest, search, and manage
continuously generated time series data. They provide a simpler way to split
data across multiple indices and still query it via a single named resource.

See the <<data-streams,Data streams documentation>> to get started.
// end::notable-highlights[]


// tag::notable-highlights[]
[discrete]
=== Enable fully concurrent snapshot operations

Snapshot operations can now execute in a fully concurrent manner.

* Create and delete operations can be started in any order
* Delete operations wait for snapshot finalization to finish, are batched
  as much as possible to improve efficiency and, once enqueued in the
  cluster state, prevent new snapshots from starting on data nodes until
  executed
* Snapshot creation is completely concurrent across shards, but per shard
  snapshots are linearized for each repository, as are snapshot
  finalizations

// end::notable-highlights[]


// tag::notable-highlights[]
[float]
=== Improve speed and memory usage of multi-bucket aggregations

Before {minor-version}, many of our more complex aggregations made a simplifying
assumption that required that they duplicate many data structures once per
bucket that contained them. The most expensive of these weighed in at a
couple of kilobytes each. So for an aggregation like:

[source,console]
----
POST _search
{
  "aggs": {
    "date": {
      "date_histogram": { "field": "timestamp", "calendar_interval": "day" },
      "aggs": {
        "ips": {
          "terms": { "field": "ip" }
        }
      }
    }
  }
}
----

When run over three years, this aggregation spends a couple of megabytes
just on bucket accounting. More deeply nested aggregations spend even more
on this overhead. {es} {minor-version} removes all of this overhead, which
should allow us to run better in lower memory environments.

As a bonus we wrote quite a few Rally benchmarks for aggregations to make
sure that these tests didn't slow down aggregations, so now we can think
much more scientifically about aggregation performance. The benchmarks
suggest that these changes don't affect simple aggregation trees and speed
up complex aggregation trees of similar or higher depth than the example
above. Your actual performance changes will vary but this optimization
should help!
// end::notable-highlights[]


[float]
=== Allow index filtering in field capabilities API

You can now supply an `index_filter` to the <<search-field-caps,field
capabilities API>>. Indices are filtered from the response if the provided
query rewrites to `match_none` on every shard.


[float]
=== Support `terms` and `rare_terms` aggregations in transforms

Transforms now support the `terms` and `rare_terms` aggregations. The
default behavior is that the results are collapsed in the following manner:

[source,txt]
----
<AGG_NAME>.<BUCKET_NAME>.<SUBAGGS...>...
----

Or if no sub-aggregations exist:

[source,txt]
----
<AGG_NAME>.<BUCKET_NAME>.<_doc_count>
----

The mapping is also defined as `flattened` by default. This is to avoid
field explosion while still providing (limited) search and aggregation
capabilities.

// tag::notable-highlights[]
[float]
=== Optimize `date_histograms` across daylight savings time

Rounding dates on a shard that contains a daylight savings time transition
is currently drastically slower than when a shard contains dates
only on one side of the DST transition, and also generates a large number
of short-lived objects in memory. {es} {minor-version} has a revised and
far more efficient implemention that adds only a comparatively small
overhead to requests.

// end::notable-highlights[]

// tag::notable-highlights[]
[float]
=== Improved resilience to network disruption

{es} now has mechansisms to safely resume peer recoveries when there is
network disruption, which would previously have failed any in-progress peer
recoveries.
// end::notable-highlights[]


// tag::notable-highlights[]
[float]
=== Wildcard field optimised for wildcard queries

{es} now supports a `wildcard` field type, which stores values optimised
for wildcard grep-like queries. While such queries are possible with other
field types, they suffer from constraints that limit their usefulness.

This field type is especially well suited for running grep-like queries on
log lines. See the <<wildcard,wildcard datatype>> documentation for more
information.
// end::notable-highlights[]


// tag::notable-highlights[]
[float]
=== Indexing metrics and back pressure

{es} {minor-version} now tracks metrics about the number of indexing
request bytes that are outstanding at each point in the indexing process
(coordinating, primary, and replication). These metrics are exposed in the
node stats API. Additionally, the new setting
`indexing_pressure.memory.limit` controls the maximum number of bytes that
can be outstanding, which is 10% of the heap by default. Once this number
of bytes from a node's heap is consumed by outstanding indexing bytes, {es}
will start rejecting new coordinating and primary requests.

Additionally, since a failed replication operation can fail a replica, {es}
will assign 1.5X limit for the number of replication bytes.
Only replication bytes can trigger this limit. If replication bytes
increase to high levels, the node will stop accepting new coordinating and
primary operations until the replication work load has dropped.
// end::notable-highlights[]

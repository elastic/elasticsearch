[[retrievers-overview]]
=== Retrievers

A retriever is an abstraction that was added to the Search API in *8.14.0* and was made generally available in *8.16.0*.
This abstraction enables the configuration of multi-stage retrieval pipelines within a single `_search` call.
This simplifies your search application logic, because you no longer need to configure complex searches via multiple {es} calls or implement additional client-side logic to combine results from different queries.

This document provides a general overview of the retriever abstraction.
For implementation details, including notable restrictions, check out the
<<retriever,reference documentation>> in the `_search` API docs.

[discrete]
[[retrievers-overview-types]]
==== Retriever types

Retrievers come in various types, each tailored for different search operations.
The following retrievers are currently available:

* <<standard-retriever,*Standard Retriever*>>.
Returns top documents from a traditional https://www.elastic.co/guide/en/elasticsearch/reference/master/query-dsl.html[query].
Mimics a traditional query but in the context of a retriever framework.
This ensures backward compatibility as existing `_search` requests remain supported.
That way you can transition to the new abstraction at your own pace without mixing syntaxes.
* <<knn-retriever,*kNN Retriever*>>.
Returns top documents from a <<search-api-knn,knn search>>, in the context of a retriever framework.
* <<rrf-retriever,*RRF Retriever*>>.
Combines and ranks multiple first-stage retrievers using the reciprocal rank fusion (RRF) algorithm.
Allows you to combine multiple result sets with different relevance indicators into a single result set.
An RRF retriever is a *compound retriever*, where its `filter` element is propagated to its sub retrievers.
* <<rule-retriever,*Rule Retriever*>>.
Applies <<query-rules,query rules>> to the query before returning results.
* <<text-similarity-reranker-retriever,*Text Similarity Re-ranker Retriever*>>.
Used for <<semantic-reranking,semantic reranking>>.
Requires first creating a `rerank` task using the <<put-inference-api,{es} Inference API>>.

[discrete]
==== What makes retrievers useful?

Here's an overview of what makes retrievers useful and how they differ from regular queries.

. *Simplified user experience*.
Retrievers simplify the user experience by allowing entire retrieval pipelines to be configured in a single API call.
This maintains backward compatibility with traditional query elements by automatically translating them to the appropriate retriever.
. *Structured retrieval*.
Retrievers provide a more structured way to define search operations.
They allow searches to be described using a "retriever tree", a hierarchical structure that clarifies the sequence and logic of operations, making complex searches more understandable and manageable.
. *Composability and flexibility*.
Retrievers enable flexible composability, allowing you to build pipelines and seamlessly integrate different retrieval strategies into these pipelines.
Retrievers make it easy to test out different retrieval strategy combinations.
. *Compound operations*.
A retriever can have sub retrievers.
This allows complex nested searches where the results of one retriever feed into another, supporting sophisticated querying strategies that might involve multiple stages or criteria.
. *Retrieval as a first-class concept*.
Unlike traditional queries, where the query is a part of a larger search API call, retrievers are designed as standalone entities that can be combined or used in isolation.
This enables a more modular and flexible approach to constructing searches.
. *Enhanced control over document scoring and ranking*.
Retrievers allow for more explicit control over how documents are scored and filtered.
For instance, you can specify minimum score thresholds, apply complex filters without affecting scoring, and use parameters like `terminate_after` for performance optimizations.
. *Integration with existing {es} functionalities*.
Even though retrievers can be used instead of existing `_search` API syntax (like the
`query` and `knn`), they are designed to integrate seamlessly with things like pagination (`search_after`) and sorting.
They also maintain compatibility with aggregation operations by treating the combination of all leaf retrievers as
`should` clauses in a boolean query.
. *Cleaner separation of concerns*.
When using compound retrievers, only the query element is allowed, which enforces a cleaner separation of concerns and prevents the complexity that might arise from overly nested or interdependent configurations.

[discrete]
[[retrievers-overview-example]]
==== Examples

The following example demonstrates the powerful queries that we can now compose, and how retrievers simplify this process.

To show the full functionality, in this exercise, we'll assume that we have access to a <<semantic-reranking-models,reranker model>> through the inference service,
as well as access to <<infer-service-elser,ELSER>>, for building semantic queries.

To begin with, we'll set up the necessary services and have them in place for later use.

[source,js]
----
// Setup rerank task stored as `my-awesome-rerank-model`
PUT _inference/rerank/my-awesome-rerank-model
{
 "service": "cohere",
 "service_settings": {
   "model_id": "rerank-english-v3.0",
   "api_key": "{{COHERE_API_KEY}}"
 }
}
----
//NOTCONSOLE

[source,js]
----
// Setup ELSER as `my-elser-endpoint`
PUT _inference/sparse_embedding/my-elser-endpoint
{
 "service": "elser",
 "service_settings": {
   "num_allocations": 1,
   "num_threads": 1
 },
 "task_settings": {}
}
----
//NOTCONSOLE

Now that we have our services in place, lets create the `retrievers_example` index, and add some documents to it.
[source,js]
----
PUT retrievers_example
{
   "mappings": {
       "properties": {
           "vector": {
               "type": "dense_vector",
               "dims": 3,
               "similarity": "l2_norm",
               "index": true
           },
           "text": {
               "type": "text",
               "copy_to": "inference_field"
           },
           "year": {
               "type": "integer"
           },
           "topic": {
               "type": "keyword"
           },
           "inference_field": {
               "type": "semantic_text",
               "inference_id": "my-elser-endpoint"
           }
       }
   }
}
----
//NOTCONSOLE

[source,js]
----
POST /retrievers_example/_doc/1
{
 "vector": [0.23, 0.67, 0.89],
 "text": "Large language models are revolutionizing information retrieval by boosting search precision, deepening contextual understanding, and reshaping user experiences in data-rich environments.",
 "year": 2024,
 "topic": ["llm", "ai", "information_retrieval"]
}

POST /retrievers_example/_doc/2
{
 "vector": [0.12, 0.56, 0.78],
 "text": "Artificial intelligence is transforming medicine, from advancing diagnostics and tailoring treatment plans to empowering predictive patient care for improved health outcomes.",
 "year": 2023,
 "topic": ["ai", "medicine"]
}

POST /retrievers_example/_doc/3
{
 "vector": [0.45, 0.32, 0.91],
  "text": "AI is redefining security by enabling advanced threat detection, proactive risk analysis, and dynamic defenses against increasingly sophisticated cyber threats.",
 "year": 2024,
 "topic": ["ai", "security"]
}

POST /retrievers_example/_doc/4
{
 "vector": [0.34, 0.21, 0.98],
 "text": "Elastic introduces Elastic AI Assistant, the open, generative AI sidekick powered by ESRE to democratize cybersecurity and enable users of every skill level.",
 "year": 2023,
 "topic": ["ai", "elastic", "assistant"]
}

POST /retrievers_example/_doc/5
{
 "vector": [0.11, 0.65, 0.47],
 "text": "Learn how to spin up a deployment of our hosted Elasticsearch Service and use Elastic Observability to gain deeper insight into the behavior of your applications and systems.",
 "year": 2024,
 "topic": ["documentation", "observability", "elastic"]
}

----
//NOTCONSOLE

Now that we also have our documents in place, let's try to run some queries using retrievers.

include::retrievers_examples.asciidoc[tag=basic-rrf-retriever-with-semantic-query]
include::retrievers_examples.asciidoc[tag=rrf-retriever-with-collapse]
include::retrievers_examples.asciidoc[tag=text-similarity-reranker-on-top-of-rrf]
include::retrievers_examples.asciidoc[tag=rrf-on-top-of-semantic-reranker]
include::retrievers_examples.asciidoc[tag=chaining-text-similarity-reranker-retrievers]
include::retrievers_examples.asciidoc[tag=rrf-retriever-with-aggs]

[discrete]
[[retrievers-overview-glossary]]
==== Glossary

Here are some important terms:

* *Retrieval Pipeline*.
Defines the entire retrieval and ranking logic to produce top hits.
* *Retriever Tree*.
A hierarchical structure that defines how retrievers interact.
* *First-stage Retriever*.
Returns an initial set of candidate documents.
* *Compound Retriever*.
Builds on one or more retrievers, enhancing document retrieval and ranking logic.
* *Combiners*.
Compound retrievers that merge top hits from multiple sub-retrievers.
* *Rerankers*.
Special compound retrievers that reorder hits and may adjust the number of hits, with distinctions between first-stage and second-stage rerankers.

[discrete]
[[retrievers-overview-play-in-search]]
==== Retrievers in action

The Search Playground builds Elasticsearch queries using the retriever abstraction.
It automatically detects the fields and types in your index and builds a retriever tree based on your selections.

You can use the Playground to experiment with different retriever configurations and see how they affect search results.

Refer to the {kibana-ref}/playground.html[Playground documentation] for more information.

[discrete]
[[retrievers-overview-api-reference]]
==== API reference

For implementation details, including notable restrictions, check out the <<retriever,reference documentation>> in the Search API docs.

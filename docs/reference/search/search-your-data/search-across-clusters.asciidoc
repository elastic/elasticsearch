[[modules-cross-cluster-search]]
== Search across clusters

*{ccs-cap}* lets you run a single search request against one or more remote
clusters. For example, you can use a {ccs} to filter and analyze log data stored
on clusters in different data centers.

[discrete]
[[ccs-supported-apis]]
=== Supported APIs

The following APIs support {ccs}:

* <<search-search,Search>>
* <<async-search,Async search>>
* <<search-multi-search,Multi search>>
* <<search-template,Search template>>
* <<multi-search-template,Multi search template>>
* <<search-field-caps,Field capabilities>>
* {painless}/painless-execute-api.html[Painless execute API]
* experimental:[] <<eql-search-api,EQL search>>
* experimental:[] <<sql-search-api,SQL search>>
* experimental:[] <<search-vector-tile-api,Vector tile search>>

[discrete]
[[ccs-prereqs]]
=== Prerequisites

* {ccs-cap} requires remote clusters. To set up remote clusters on {ess},
see link:{cloud}/ec-enable-ccs.html[configure remote clusters on {ess}]. If you
run {es} on your own hardware, see <<remote-clusters>>.
+
To ensure your remote cluster configuration supports {ccs}, see
<<ccs-supported-configurations>>.

* For full {ccs} capabilities, the local and remote cluster must be on the same
{subscriptions}[subscription level].

* The local coordinating node must have the
<<remote-node,`remote_cluster_client`>> node role.

[[ccs-gateway-seed-nodes]]
* If you use <<sniff-mode,sniff mode>>, the local coordinating node
must be able to connect to seed and gateway nodes on the remote cluster.
+
We recommend using gateway nodes capable of serving as coordinating nodes.
The seed nodes can be a subset of these gateway nodes.

[[ccs-proxy-mode]]
* If you use <<proxy-mode,proxy mode>>, the local coordinating node must be able
to connect to the configured `proxy_address`. The proxy at this address must be
able to route connections to gateway and coordinating nodes on the remote
cluster.

* {ccs-cap} requires different security privileges on the local cluster and
remote cluster. See <<remote-clusters-privileges-ccs>> and
<<clusters-privileges-ccs-kibana>>.

[discrete]
[[ccs-example]]
=== {ccs-cap} examples

[discrete]
[[ccs-remote-cluster-setup]]
==== Remote cluster setup

The following <<cluster-update-settings,cluster update settings>> API request
adds three remote clusters: `cluster_one`, `cluster_two`, and `cluster_three`.

[source,console]
--------------------------------
PUT _cluster/settings
{
  "persistent": {
    "cluster": {
      "remote": {
        "cluster_one": {
          "seeds": [
            "127.0.0.1:9300"
          ]
        },
        "cluster_two": {
          "seeds": [
            "127.0.0.1:9301"
          ]
        },
        "cluster_three": {
          "seeds": [
            "127.0.0.1:9302"
          ]
        }
      }
    }
  }
}
--------------------------------
// TEST[setup:host]
// TEST[s/127.0.0.1:930\d+/\${transport_host}/]

[discrete]
[[ccs-search-remote-cluster]]
==== Search a single remote cluster

In the search request, you specify data streams and indices on a remote cluster
as `<remote_cluster_name>:<target>`.

The following <<search-search,search>> API request searches the
`my-index-000001` index on a single remote cluster, `cluster_one`.

[source,console]
--------------------------------------------------
GET /cluster_one:my-index-000001/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  },
  "_source": ["user.id", "message", "http.response.status_code"]
}
--------------------------------------------------
// TEST[continued]
// TEST[setup:my_index]

The API returns the following response:

[source,console-result]
--------------------------------------------------
{
  "took": 150,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "failed": 0,
    "skipped": 0
  },
  "_clusters": {
    "total": 1,
    "successful": 1,
    "skipped": 0
  },
  "hits": {
    "total" : {
        "value": 1,
        "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "cluster_one:my-index-000001", <1>
        "_id": "0",
        "_score": 1,
        "_source": {
          "user": {
            "id": "kimchy"
          },
          "message": "GET /search HTTP/1.1 200 1070000",
          "http": {
            "response":
              {
                "status_code": 200
              }
          }
        }
      }
    ]
  }
}
--------------------------------------------------
// TESTRESPONSE[s/"took": 150/"took": "$body.took"/]
// TESTRESPONSE[s/"max_score": 1/"max_score": "$body.hits.max_score"/]
// TESTRESPONSE[s/"_score": 1/"_score": "$body.hits.hits.0._score"/]

<1> The search response body includes the name of the remote cluster in the
`_index` parameter.

[discrete]
[[ccs-search-multi-remote-cluster]]
==== Search multiple remote clusters

The following <<search,search>> API request searches the `my-index-000001` index on
three clusters:

* Your local cluster
* Two remote clusters, `cluster_one` and `cluster_two`

[source,console]
--------------------------------------------------
GET /my-index-000001,cluster_one:my-index-000001,cluster_two:my-index-000001/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  },
  "_source": ["user.id", "message", "http.response.status_code"]
}
--------------------------------------------------
// TEST[continued]

The API returns the following response:

[source,console-result]
--------------------------------------------------
{
  "took": 150,
  "timed_out": false,
  "num_reduce_phases": 4,
  "_shards": {
    "total": 3,
    "successful": 3,
    "failed": 0,
    "skipped": 0
  },
  "_clusters": {
    "total": 3,
    "successful": 3,
    "skipped": 0
  },
  "hits": {
    "total" : {
        "value": 3,
        "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "my-index-000001", <1>
        "_id": "0",
        "_score": 2,
        "_source": {
          "user": {
            "id": "kimchy"
          },
          "message": "GET /search HTTP/1.1 200 1070000",
          "http": {
            "response":
              {
                "status_code": 200
              }
          }
        }
      },
      {
        "_index": "cluster_one:my-index-000001", <2>
        "_id": "0",
        "_score": 1,
        "_source": {
          "user": {
            "id": "kimchy"
          },
          "message": "GET /search HTTP/1.1 200 1070000",
          "http": {
            "response":
              {
                "status_code": 200
              }
          }
        }
      },
      {
        "_index": "cluster_two:my-index-000001", <3>
        "_id": "0",
        "_score": 1,
        "_source": {
          "user": {
            "id": "kimchy"
          },
          "message": "GET /search HTTP/1.1 200 1070000",
          "http": {
            "response":
              {
                "status_code": 200
              }
          }
        }
      }
    ]
  }
}
--------------------------------------------------
// TESTRESPONSE[s/"took": 150/"took": "$body.took"/]
// TESTRESPONSE[s/"max_score": 1/"max_score": "$body.hits.max_score"/]
// TESTRESPONSE[s/"_score": 1/"_score": "$body.hits.hits.0._score"/]
// TESTRESPONSE[s/"_score": 2/"_score": "$body.hits.hits.1._score"/]

<1> This document's `_index` parameter doesn't include a cluster name. This
means the document came from the local cluster.
<2> This document came from `cluster_one`.
<3> This document came from `cluster_two`.





[discrete]
[[ccs-async-search-minimize-roundtrips-true]]
=== Using async search for {ccs} with ccs_minimize_roundtrips=true

Remote clusters can be queried asynchronously using the <<async-search,async search>> API.
Async searches accept a <<ccs-minimize-roundtrips,`ccs_minimize_roundtrips`>> parameter
that defaults to `false`. See <<ccs-min-roundtrips>> to learn more about this option.

The following request does an asynchronous search of the `my-index-000001` index using
`ccs_minimize_roundtrips=true` against three clusters:

* The local cluster, with 8 shards
* Two remote clusters, `cluster_one` and `cluster_two`, with 10 shards each

[source,console]
--------------------------------------------------
POST /my-index-000001,cluster_one:my-index-000001,cluster_two:my-index-000001/_async_search?ccs_minimize_roundtrips=true
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  },
  "_source": ["user.id", "message", "http.response.status_code"]
}
--------------------------------------------------
// TEST[continued]
// TEST[s/ccs_minimize_roundtrips=true/ccs_minimize_roundtrips=true&wait_for_completion_timeout=1s&keep_on_completion=true/]


The API returns the following response:

[source,console-result]
--------------------------------------------------
{
  "id": "FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=", <1>
  "is_partial": true,
  "is_running": true,
  "start_time_in_millis": 1685563581380,
  "expiration_time_in_millis": 1685995581380,
  "response": {
    "took": 1020,
    "timed_out": false,
    "num_reduce_phases": 0,
    "_shards": {
      "total": 8,     <2>
      "successful": 0,
      "failed": 0,
      "skipped": 0
    },
    "_clusters": {    <3>
      "total" : 3,
      "successful" : 0,
      "skipped": 0
    },
    "hits": {
      "total" : {
          "value": 0,
          "relation": "eq"
      },
      "max_score": null,
      "hits": []
    }
  }
}
--------------------------------------------------
// TESTRESPONSE[s/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=/$body.id/]
// TESTRESPONSE[s/"is_partial": true/"is_partial": $body.is_partial/]
// TESTRESPONSE[s/"is_running": true/"is_running": $body.is_running/]
// TESTRESPONSE[s/1685563581380/$body.start_time_in_millis/]
// TESTRESPONSE[s/1685995581380/$body.expiration_time_in_millis/]
// TESTRESPONSE[s/"num_reduce_phases": 0/"num_reduce_phases": "$body.response.num_reduce_phases"/]
// TESTRESPONSE[s/"took": 1020/"took": "$body.response.took"/]
// TESTRESPONSE[s/"total": 8/"total": $body.response._shards.total/]
// TESTRESPONSE[s/"successful": 0/"successful": $body.response._shards.successful/]
// TESTRESPONSE[s/"successful" : 0/"successful": $body.response._clusters.successful/]
// TESTRESPONSE[s/"value": 0/"value": "$body.response.hits.total.value"/]
// TESTRESPONSE[s/"max_score": null/"max_score": "$body.response.hits.max_score"/]
// TESTRESPONSE[s/"hits": \[\]/"hits": $body.response.hits.hits/]


<1> The async search id.
<2> When `ccs_minimize_roundtrips` = `true` and searches on the remote clusters
are still running, this section indicates the number of shards in scope for the
local cluster only. This will be updated to include the total number of shards
across all clusters only when the search is completed.
<3> The `_clusters` section indicates that 3 clusters are in scope for the search
and all are currently running (since `successful` and `skipped` both equal 0).



If you query the <<get-async-search,get async search>> endpoint while the query is
still running, you will see an update in the `_clusters` and `_shards` section of
the response when the local search has finished.

[source,console]
--------------------------------------------------
GET /_async_search/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=
--------------------------------------------------
// TEST[skip: terminated_early is absent from final results so is hard to reproduce here]

Response:

[source,console-result]
--------------------------------------------------
{
  "id": "FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=",
  "is_partial": true,
  "is_running": true,
  "start_time_in_millis": 1685564911108,
  "expiration_time_in_millis": 1685996911108,
  "response": {
    "took": 11164,
    "timed_out": false,
    "terminated_early": false,
    "_shards": {
      "total": 8,
      "successful": 8,  <1>
      "skipped": 0,
      "failed": 0
    },
    "_clusters": {
      "total": 3,
      "successful": 1,  <2>
      "skipped": 0
    },
    "hits": {
      "total": {
        "value": 167,  <3>
        "relation": "eq"
      },
      "max_score": null,
      "hits": []
    }
  }
}
--------------------------------------------------
// TEST[skip: terminated_early is absent from final results so is hard to reproduce here]


<1> All the local cluster shards have completed.
<2> The local cluster search has completed, so the "successful" clusters entry
is set to 1. The `_clusters` response section will not be updated for the remote clusters
until all remote searches have finished (either successfully or been skipped).
<3> Number of hits from the local cluster search. Final hits are not
shown until searches on all clusters have been completed and merged.




After searches on all the clusters have completed, when you query the
<<get-async-search,get async search>> endpoint, you will see the final
status of the `_clusters` and `_shards` section as well as the hits.

[source,console]
--------------------------------------------------
GET /_async_search/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=
--------------------------------------------------
// TEST[continued s/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=/\${body.id}/]


Response:

[source,console-result]
--------------------------------------------------
{
  "id": "FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=",
  "is_partial": false,
  "is_running": false,
  "start_time_in_millis": 1685564911108,
  "expiration_time_in_millis": 1685996911108,
  "response": {
    "took": 27619,
    "timed_out": false,
    "num_reduce_phases": 4,
    "_shards": {
      "total": 28,
      "successful": 28,  <1>
      "skipped": 0,
      "failed": 0
    },
    "_clusters": {
      "total": 3,
      "successful": 3,   <2>
      "skipped": 0
    },
    "hits": {
      "total": {
        "value": 1067,
        "relation": "eq"
      },
      "max_score": 1.8293576,
      "hits": [...list of hits here...]
    }
  }
}
--------------------------------------------------
// TESTRESPONSE[s/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=/$body.id/]
// TESTRESPONSE[s/"is_partial": true/"is_partial": $body.is_partial/]
// TESTRESPONSE[s/"is_running": true/"is_running": $body.is_running/]
// TESTRESPONSE[s/1685564911108/$body.start_time_in_millis/]
// TESTRESPONSE[s/1685996911108/$body.expiration_time_in_millis/]
// TESTRESPONSE[s/"took": 27619/"took": "$body.response.took"/]
// TESTRESPONSE[s/"total": 28/"total": $body.response._shards.total/]
// TESTRESPONSE[s/"successful": 28/"successful": $body.response._shards.successful/]
// TESTRESPONSE[s/"successful": 3/"successful": $body.response._clusters.successful/]
// TESTRESPONSE[s/"value": 1067/"value": "$body.response.hits.total.value"/]
// TESTRESPONSE[s/"relation": "eq"/"relation": "$body.response.hits.total.relation"/]
// TESTRESPONSE[s/"max_score": 1.8293576/"max_score": "$body.response.hits.max_score"/]
// TESTRESPONSE[s/"hits": \[...list of hits here...\]/"hits": $body.response.hits.hits/]


<1> The `_shards` section is now updated to show that 28 total shards
were searched across all clusters and that all were successful.
<2> The `_clusters` section shows that searches on all 3 clusters were successful.



[discrete]
[[ccs-async-search-minimize-roundtrips-false]]
=== Using async search for {ccs} with ccs_minimize_roundtrips=false

The `_shards` and `_clusters` section of the response behave differently
when `ccs_minimize_roundtrips` is `false` in asynchronous searches.

Key differences are:

. The `_shards` section total count will be accurate immediately as the total number
of shards is gathered from all clusters before the search starts.

. The `_shards` section will be incrementally updated as searches on individual
shards complete, so you will get a more accurate accounting of progress during a
long-running search compared to when minimize roundtrips is used.

. The `_cluster` section starts off in its final state, showing which clusters
were successful or skipped based on gathering shard information before the actual
search phase against each shard begins.

Example using the same set up as in the previous section (`ccs_minimize_roundtrips=true`):

[source,console]
--------------------------------------------------
GET /my-index-000001,cluster_one:my-index-000001,cluster_two:my-index-000001/_async_search?ccs_minimize_roundtrips=false
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  },
  "_source": ["user.id", "message", "http.response.status_code"]
}
--------------------------------------------------
// TEST[continued]
// TEST[s/ccs_minimize_roundtrips=false/ccs_minimize_roundtrips=false&wait_for_completion_timeout=1s&keep_on_completion=true/]


The API returns the following response if the query takes longer than
the `wait_for_completion_timeout` duration (see <<async-search>>).

[source,console-result]
--------------------------------------------------
{
  "id": "FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=",
  "is_partial": true,
  "is_running": true,
  "start_time_in_millis": 1685563581380,
  "expiration_time_in_millis": 1685995581380,
  "response": {
    "took": 1020,
    "timed_out": false,
    "num_reduce_phases": 0,
    "_shards": {
      "total": 28,     <1>
      "successful": 0,
      "failed": 0,
      "skipped": 0
    },
    "_clusters": {
      "total" : 3,
      "successful": 3,  <2>
      "skipped": 0
    },
    "hits": {
      "total" : {
          "value": 0,
          "relation": "eq"
      },
      "max_score": null,
      "hits": []
    }
  }
}
--------------------------------------------------
// TESTRESPONSE[s/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=/$body.id/]
// TESTRESPONSE[s/"is_partial": true/"is_partial": $body.is_partial/]
// TESTRESPONSE[s/"is_running": true/"is_running": $body.is_running/]
// TESTRESPONSE[s/1685563581380/$body.start_time_in_millis/]
// TESTRESPONSE[s/1685995581380/$body.expiration_time_in_millis/]
// TESTRESPONSE[s/"num_reduce_phases": 0/"num_reduce_phases": "$body.response.num_reduce_phases"/]
// TESTRESPONSE[s/"took": 1020/"took": "$body.response.took"/]
// TESTRESPONSE[s/"total": 28/"total": $body.response._shards.total/]
// TESTRESPONSE[s/"successful": 0/"successful": $body.response._shards.successful/]
// TESTRESPONSE[s/"successful": 3/"successful": $body.response._clusters.successful/]
// TESTRESPONSE[s/"value": 0/"value": "$body.response.hits.total.value"/]
// TESTRESPONSE[s/"max_score": null/"max_score": "$body.response.hits.max_score"/]
// TESTRESPONSE[s/"hits": \[\]/"hits": $body.response.hits.hits/]

<1> All shards from all clusters in scope for the search are listed here. Watch this
section for updates to monitor search progress.
<2> The `_clusters` section shows that shard information was successfully
gathered from all 3 clusters and that all will be searched (none are being skipped).




[discrete]
[[skip-unavailable-clusters]]
=== Optional remote clusters

By default, a {ccs} fails if a remote cluster in the request returns an
error or is unavailable. Use the `skip_unavailable` cluster
setting to mark a specific remote cluster as optional for {ccs}.

If `skip_unavailable` is `true`, a {ccs}:

* Skips the remote cluster if its nodes are unavailable during the search. The
response's `_cluster.skipped` value contains a count of any skipped clusters.

* Ignores errors returned by the remote cluster, such as errors related to
unavailable shards or indices. This can include errors related to search
parameters such as <<api-multi-index,`allow_no_indices`>> and
<<api-multi-index,`ignore_unavailable`>>.

* Ignores the <<search-partial-responses,`allow_partial_search_results`>>
parameter and the related `search.default_allow_partial_results` cluster setting
when searching the remote cluster. This means searches on the remote cluster may
return partial results.

The following <<cluster-update-settings,cluster update settings>>
API request changes `cluster_two`'s `skip_unavailable` setting to `true`.

[source,console]
--------------------------------
PUT _cluster/settings
{
  "persistent": {
    "cluster.remote.cluster_two.skip_unavailable": true
  }
}
--------------------------------
// TEST[continued]

If `cluster_two` is disconnected or unavailable during a {ccs}, {es} won't
include matching documents from that cluster in the final results.

[discrete]
[[ccs-network-delays]]
=== How {ccs} handles network delays

Because {ccs} involves sending requests to remote clusters, any network delays
can impact search speed. To avoid slow searches, {ccs} offers two options for
handling network delays:

<<ccs-min-roundtrips,Minimize network roundtrips>>::
By default, {es} reduces the number of network roundtrips between remote
clusters. This reduces the impact of network delays on search speed. However,
{es} can't reduce network roundtrips for large search requests, such as those
including a <<scroll-search-results, scroll>> or
<<inner-hits,inner hits>>.
+
See <<ccs-min-roundtrips>> to learn how this option works.

<<ccs-unmin-roundtrips, Don't minimize network roundtrips>>:: For search
requests that include a scroll or inner hits, {es} sends multiple outgoing and
ingoing requests to each remote cluster. You can also choose this option by
setting the <<ccs-minimize-roundtrips,`ccs_minimize_roundtrips`>> parameter to
`false`. While typically slower, this approach may work well for networks with
low latency.
+
See <<ccs-unmin-roundtrips>> to learn how this option works.

NOTE: The <<search-vector-tile-api,vector tile search API>> always minimizes
network roundtrips and doesn't include the `ccs_minimize_roundtrips` parameter.

NOTE: The <<approximate-knn, Approximate kNN search>> doesn't support minimizing
network roundtrips, and sets the parameter `ccs_minimize_roundtrips` to `false`.

[discrete]
[[ccs-min-roundtrips]]
==== Minimize network roundtrips

Here's how {ccs} works when you minimize network roundtrips.

. You send a {ccs} request to your local cluster. A coordinating node in that
cluster receives and parses the request.
+
image:images/ccs/ccs-min-roundtrip-client-request.svg[]

. The coordinating node sends a single search request to each cluster, including
the local cluster. Each cluster performs the search request independently,
applying its own cluster-level settings to the request.
+
image:images/ccs/ccs-min-roundtrip-cluster-search.svg[]

. Each remote cluster sends its search results back to the coordinating node.
+
image:images/ccs/ccs-min-roundtrip-cluster-results.svg[]

. After collecting results from each cluster, the coordinating node returns the
final results in the {ccs} response.
+
image:images/ccs/ccs-min-roundtrip-client-response.svg[]

[discrete]
[[ccs-unmin-roundtrips]]
==== Don't minimize network roundtrips

Here's how {ccs} works when you don't minimize network roundtrips.

. You send a {ccs} request to your local cluster. A coordinating node in that
cluster receives and parses the request.
+
image:images/ccs/ccs-min-roundtrip-client-request.svg[]

. The coordinating node sends a "search shards" transport layer request
to each remote cluster to have them to perform a "can match" search to determine
which shards on each cluster should be searched.
+
image:images/ccs/ccs-min-roundtrip-cluster-search.svg[]

. Each remote cluster sends its response back to the coordinating node.
This response contains information about the indices and shards the {ccs}
request will be executed on.
+
image:images/ccs/ccs-min-roundtrip-cluster-results.svg[]

. The coordinating node sends a search request to each shard, including those in
its own cluster. Each shard performs the search request independently.
+
[WARNING]
====
When network roundtrips aren't minimized, the search is executed as if all data
were in the coordinating node's cluster. We recommend updating cluster-level
settings that limit searches, such as `action.search.shard_count.limit`,
`pre_filter_shard_size`, and `max_concurrent_shard_requests`, to account for
this. If these limits are too low, the search may be rejected.
====
+
image:images/ccs/ccs-dont-min-roundtrip-shard-search.svg[]

. Each shard sends its search results back to the coordinating node.
+
image:images/ccs/ccs-dont-min-roundtrip-shard-results.svg[]

. After collecting results from each cluster, the coordinating node returns the
final results in the {ccs} response.
+
image:images/ccs/ccs-min-roundtrip-client-response.svg[]

[discrete]
[[ccs-supported-configurations]]
=== Supported {ccs} configurations

In 8.0+, Elastic supports searches from a local cluster to a remote cluster
running:

* The previous minor version.
* The same version.
* A newer minor version in the same major version.

Elastic also supports searches from a local cluster running the last minor
version of a major version to a remote cluster running any minor version in the
following major version. For example, a local 7.17 cluster can search any
remote 8.x cluster.

[[ccs-version-compatibility]]
include::{es-repo-dir}/search/search-your-data/ccs-version-compat-matrix.asciidoc[]

IMPORTANT: For the <<eql-search-api,EQL search API>>, the local and remote
clusters must use the same {es} version if they have versions prior to 7.17.7 (included) or prior to 8.5.1 (included).

For example, a local 8.0 cluster can search a remote 7.17 or any remote 8.x
cluster. However, a search from a local 8.0 cluster to a remote 7.16 or 6.8
cluster is not supported.

Only features that exist across all searched clusters are supported. Using a
feature with a remote cluster where the feature is not supported will result in
undefined behavior.

A {ccs} using an unsupported configuration may still work. However, such
searches aren't tested by Elastic, and their behavior isn't guaranteed.

[discrete]
[[ensure-ccs-support]]
==== Ensure {ccs} support

The simplest way to ensure your clusters support {ccs} is to keep each cluster
on the same version of {es}. If you need to maintain clusters with different
versions, you can:

* Maintain a dedicated cluster for {ccs}. Keep this cluster on the earliest
version needed to search the other clusters. For example, if you have 7.17 and 8.x clusters, you can maintain a dedicated 7.17 cluster to use
as the local cluster for {ccs}.

* Keep each cluster no more than one minor version apart. This lets you use any
cluster as the local cluster when running a {ccs}.

[discrete]
[[ccs-during-upgrade]]
==== {ccs-cap} during an upgrade

You can still search a remote cluster while performing a
rolling upgrade on the local cluster. However, the local
coordinating node's "upgrade from" and "upgrade to" version must be compatible
with the remote cluster's gateway node.

WARNING: Running multiple versions of {es} in the same cluster beyond the
duration of an upgrade is not supported.

For more information about upgrades, see
{stack-ref}/upgrading-elasticsearch.html[Upgrading {es}].

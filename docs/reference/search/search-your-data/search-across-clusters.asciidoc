[[modules-cross-cluster-search]]
== Search across clusters

*{ccs-cap}* lets you run a single search request against one or more remote
clusters. For example, you can use a {ccs} to filter and analyze log data stored
on clusters in different data centers.

[discrete]
[[ccs-supported-apis]]
=== Supported APIs

The following APIs support {ccs}:

* <<search-search,Search>>
* <<async-search,Async search>>
* <<search-multi-search,Multi search>>
* <<search-template,Search template>>
* <<multi-search-template,Multi search template>>
* <<search-field-caps,Field capabilities>>
* experimental:[] <<eql-search-api,EQL search>>
* experimental:[] <<sql-search-api,SQL search>>
* experimental:[] <<search-vector-tile-api,Vector tile search>>

[discrete]
[[ccs-prereqs]]
=== Prerequisites

* {ccs-cap} requires remote clusters. To set up remote clusters on {ess},
see link:{cloud}/ec-enable-ccs.html[configure remote clusters on {ess}]. If you
run {es} on your own hardware, see <<remote-clusters>>.
+
To ensure your remote cluster configuration supports {ccs}, see
<<ccs-supported-configurations>>.

* The local coordinating node must have the
<<remote-node,`remote_cluster_client`>> node role.

[[ccs-gateway-seed-nodes]]
* If you use <<sniff-mode,sniff mode>>, the local coordinating node
must be able to connect to seed and gateway nodes on the remote cluster.
+
We recommend using gateway nodes capable of serving as coordinating nodes.
The seed nodes can be a subset of these gateway nodes.

[[ccs-proxy-mode]]
* If you use <<proxy-mode,proxy mode>>, the local coordinating node must be able
to connect to the configured `proxy_address`. The proxy at this address must be
able to route connections to gateway and coordinating nodes on the remote
cluster.

* {ccs-cap} requires different security privileges on the local cluster and
remote cluster. See <<remote-clusters-privileges-ccs>> and
<<clusters-privileges-ccs-kibana>>.

[discrete]
[[ccs-example]]
=== {ccs-cap} examples

[discrete]
[[ccs-remote-cluster-setup]]
==== Remote cluster setup

The following <<cluster-update-settings,cluster update settings>> API request
adds three remote clusters: `cluster_one`, `cluster_two`, and `cluster_three`.

[source,console]
--------------------------------
PUT _cluster/settings
{
  "persistent": {
    "cluster": {
      "remote": {
        "cluster_one": {
          "seeds": [
            "127.0.0.1:9300"
          ]
        },
        "cluster_two": {
          "seeds": [
            "127.0.0.1:9301"
          ]
        },
        "cluster_three": {
          "seeds": [
            "127.0.0.1:9302"
          ]
        }
      }
    }
  }
}
--------------------------------
// TEST[setup:host]
// TEST[s/127.0.0.1:930\d+/\${transport_host}/]

[discrete]
[[ccs-search-remote-cluster]]
==== Search a single remote cluster

In the search request, you specify data streams and indices on a remote cluster
as `<remote_cluster_name>:<target>`.

The following <<search-search,search>> API request searches the
`my-index-000001` index on a single remote cluster, `cluster_one`.

[source,console]
--------------------------------------------------
GET /cluster_one:my-index-000001/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  },
  "_source": ["user.id", "message", "http.response.status_code"]
}
--------------------------------------------------
// TEST[continued]
// TEST[setup:my_index]

The API returns the following response:

[source,console-result]
--------------------------------------------------
{
  "took": 150,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "failed": 0,
    "skipped": 0
  },
  "_clusters": {
    "total": 1,
    "successful": 1,
    "skipped": 0
  },
  "hits": {
    "total" : {
        "value": 1,
        "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "cluster_one:my-index-000001", <1>
        "_id": "0",
        "_score": 1,
        "_source": {
          "user": {
            "id": "kimchy"
          },
          "message": "GET /search HTTP/1.1 200 1070000",
          "http": {
            "response":
              {
                "status_code": 200
              }
          }
        }
      }
    ]
  }
}
--------------------------------------------------
// TESTRESPONSE[s/"took": 150/"took": "$body.took"/]
// TESTRESPONSE[s/"max_score": 1/"max_score": "$body.hits.max_score"/]
// TESTRESPONSE[s/"_score": 1/"_score": "$body.hits.hits.0._score"/]

<1> The search response body includes the name of the remote cluster in the
`_index` parameter.

[discrete]
[[ccs-search-multi-remote-cluster]]
==== Search multiple remote clusters

The following <<search,search>> API request searches the `my-index-000001` index on
three clusters:

* Your local cluster
* Two remote clusters, `cluster_one` and `cluster_two`

[source,console]
--------------------------------------------------
GET /my-index-000001,cluster_one:my-index-000001,cluster_two:my-index-000001/_search
{
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  },
  "_source": ["user.id", "message", "http.response.status_code"]
}
--------------------------------------------------
// TEST[continued]

The API returns the following response:

[source,console-result]
--------------------------------------------------
{
  "took": 150,
  "timed_out": false,
  "num_reduce_phases": 4,
  "_shards": {
    "total": 3,
    "successful": 3,
    "failed": 0,
    "skipped": 0
  },
  "_clusters": {
    "total": 3,
    "successful": 3,
    "skipped": 0
  },
  "hits": {
    "total" : {
        "value": 3,
        "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "my-index-000001", <1>
        "_id": "0",
        "_score": 2,
        "_source": {
          "user": {
            "id": "kimchy"
          },
          "message": "GET /search HTTP/1.1 200 1070000",
          "http": {
            "response":
              {
                "status_code": 200
              }
          }
        }
      },
      {
        "_index": "cluster_one:my-index-000001", <2>
        "_id": "0",
        "_score": 1,
        "_source": {
          "user": {
            "id": "kimchy"
          },
          "message": "GET /search HTTP/1.1 200 1070000",
          "http": {
            "response":
              {
                "status_code": 200
              }
          }
        }
      },
      {
        "_index": "cluster_two:my-index-000001", <3>
        "_id": "0",
        "_score": 1,
        "_source": {
          "user": {
            "id": "kimchy"
          },
          "message": "GET /search HTTP/1.1 200 1070000",
          "http": {
            "response":
              {
                "status_code": 200
              }
          }
        }
      }
    ]
  }
}
--------------------------------------------------
// TESTRESPONSE[s/"took": 150/"took": "$body.took"/]
// TESTRESPONSE[s/"max_score": 1/"max_score": "$body.hits.max_score"/]
// TESTRESPONSE[s/"_score": 1/"_score": "$body.hits.hits.0._score"/]
// TESTRESPONSE[s/"_score": 2/"_score": "$body.hits.hits.1._score"/]

<1> This document's `_index` parameter doesn't include a cluster name. This
means the document came from the local cluster.
<2> This document came from `cluster_one`.
<3> This document came from `cluster_two`.

[discrete]
[[skip-unavailable-clusters]]
=== Optional remote clusters

By default, a {ccs} fails if a remote cluster in the request returns an
error or is unavailable. Use the `skip_unavailable` cluster
setting to mark a specific remote cluster as optional for {ccs}.

If `skip_unavailable` is `true`, a {ccs}:

* Skips the remote cluster if its nodes are unavailable during the search. The
response's `_cluster.skipped` value contains a count of any skipped clusters.

* Ignores errors returned by the remote cluster, such as errors related to
unavailable shards or indices. This can include errors related to search
parameters such as <<api-multi-index,`allow_no_indices`>> and
<<api-multi-index,`ignore_unavailable`>>.

* Ignores the <<search-partial-responses,`allow_partial_search_results`>>
parameter and the related `search.default_allow_partial_results` cluster setting
when searching the remote cluster. This means searches on the remote cluster may
return partial results.

The following <<cluster-update-settings,cluster update settings>>
API request changes `cluster_two`'s `skip_unavailable` setting to `true`.

[source,console]
--------------------------------
PUT _cluster/settings
{
  "persistent": {
    "cluster.remote.cluster_two.skip_unavailable": true
  }
}
--------------------------------
// TEST[continued]

If `cluster_two` is disconnected or unavailable during a {ccs}, {es} won't
include matching documents from that cluster in the final results.

[discrete]
[[ccs-network-delays]]
=== How {ccs} handles network delays

Because {ccs} involves sending requests to remote clusters, any network delays
can impact search speed. To avoid slow searches, {ccs} offers two options for
handling network delays:

<<ccs-min-roundtrips,Minimize network roundtrips>>::
By default, {es} reduces the number of network roundtrips between remote
clusters. This reduces the impact of network delays on search speed. However,
{es} can't reduce network roundtrips for large search requests, such as those
including a <<scroll-search-results, scroll>> or
<<inner-hits,inner hits>>.
+
See <<ccs-min-roundtrips>> to learn how this option works.

<<ccs-unmin-roundtrips, Don't minimize network roundtrips>>:: For search
requests that include a scroll or inner hits, {es} sends multiple outgoing and
ingoing requests to each remote cluster. You can also choose this option by
setting the <<ccs-minimize-roundtrips,`ccs_minimize_roundtrips`>> parameter to
`false`. While typically slower, this approach may work well for networks with
low latency.
+
See <<ccs-unmin-roundtrips>> to learn how this option works.

NOTE: The <<search-vector-tile-api,vector tile search API>> always minimizes
network roundtrips and doesn't include the `ccs_minimize_roundtrips` parameter.

[discrete]
[[ccs-min-roundtrips]]
==== Minimize network roundtrips

Here's how {ccs} works when you minimize network roundtrips.

. You send a {ccs} request to your local cluster. A coordinating node in that
cluster receives and parses the request.
+
image:images/ccs/ccs-min-roundtrip-client-request.svg[]

. The coordinating node sends a single search request to each cluster, including
the local cluster. Each cluster performs the search request independently,
applying its own cluster-level settings to the request.
+
image:images/ccs/ccs-min-roundtrip-cluster-search.svg[]

. Each remote cluster sends its search results back to the coordinating node.
+
image:images/ccs/ccs-min-roundtrip-cluster-results.svg[]

. After collecting results from each cluster, the coordinating node returns the
final results in the {ccs} response.
+
image:images/ccs/ccs-min-roundtrip-client-response.svg[]

[discrete]
[[ccs-unmin-roundtrips]]
==== Don't minimize network roundtrips

Here's how {ccs} works when you don't minimize network roundtrips.

. You send a {ccs} request to your local cluster. A coordinating node in that
cluster receives and parses the request.
+
image:images/ccs/ccs-min-roundtrip-client-request.svg[]

. The coordinating node sends a <<search-shards,search shards>> API request to
each remote cluster.
+
image:images/ccs/ccs-min-roundtrip-cluster-search.svg[]

. Each remote cluster sends its response back to the coordinating node.
This response contains information about the indices and shards the {ccs}
request will be executed on.
+
image:images/ccs/ccs-min-roundtrip-cluster-results.svg[]

. The coordinating node sends a search request to each shard, including those in
its own cluster. Each shard performs the search request independently.
+
[WARNING]
====
When network roundtrips aren't minimized, the search is executed as if all data
were in the coordinating node's cluster. We recommend updating cluster-level
settings that limit searches, such as `action.search.shard_count.limit`,
`pre_filter_shard_size`, and `max_concurrent_shard_requests`, to account for
this. If these limits are too low, the search may be rejected.
====
+
image:images/ccs/ccs-dont-min-roundtrip-shard-search.svg[]

. Each shard sends its search results back to the coordinating node.
+
image:images/ccs/ccs-dont-min-roundtrip-shard-results.svg[]

. After collecting results from each cluster, the coordinating node returns the
final results in the {ccs} response.
+
image:images/ccs/ccs-min-roundtrip-client-response.svg[]

[discrete]
[[ccs-supported-configurations]]
=== Supported {ccs} configurations

In 8.0+, Elastic supports searches from a local cluster to a remote cluster
running:

* The previous minor version.
* The same version.
* A newer minor version in the same major version.

Elastic also supports searches from a local cluster running the last minor
version of a major version to a remote cluster running any minor version in the
following major version. For example, a local 7.17 cluster can search any
remote 8.x cluster.

[[ccs-version-compatibility]]
include::{es-repo-dir}/search/search-your-data/ccs-version-compat-matrix.asciidoc[]

IMPORTANT: For the <<eql-search-api,EQL search API>>, the local and remote
clusters must use the same {es} version.

For example, a local 8.0 cluster can search a remote 7.17 or any remote 8.x
cluster. However, a search from a local 8.0 cluster to a remote 7.16 or 6.8
cluster is not supported.

Only features that exist across all searched clusters are supported. Using a
feature with a remote cluster where the feature is not supported will result in
undefined behavior.

A {ccs} using an unsupported configuration may still work. However, such
searches aren't tested by Elastic, and their behavior isn't guaranteed.

[discrete]
[[ensure-ccs-support]]
==== Ensure {ccs} support

The simplest way to ensure your clusters support {ccs} is to keep each cluster
on the same version of {es}. If you need to maintain clusters with different
versions, you can:

* Maintain a dedicated cluster for {ccs}. Keep this cluster on the earliest
version needed to search the other clusters. For example, if you have 7.17 and 8.x clusters, you can maintain a dedicated 7.17 cluster to use
as the local cluster for {ccs}.

* Keep each cluster no more than one minor version apart. This lets you use any
cluster as the local cluster when running a {ccs}.

[discrete]
[[ccs-during-upgrade]]
==== {ccs-cap} during an upgrade

You can still search a remote cluster while performing a
rolling upgrade on the local cluster. However, the local
coordinating node's "upgrade from" and "upgrade to" version must be compatible
with the remote cluster's gateway node.

WARNING: Running multiple versions of {es} in the same cluster beyond the
duration of an upgrade is not supported.

For more information about upgrades, see
{stack-ref}/upgrading-elasticsearch.html[Upgrading {es}].

import org.elasticsearch.gradle.internal.info.BuildParams
import org.elasticsearch.gradle.internal.precommit.CheckForbiddenApisTask;

apply plugin: 'elasticsearch.internal-es-plugin'
apply plugin: 'elasticsearch.internal-cluster-test'
apply plugin: 'elasticsearch.string-templates'
apply plugin: 'elasticsearch.publish'

esplugin {
  name 'x-pack-esql'
  description 'The plugin that powers ESQL for Elasticsearch'
  classname 'org.elasticsearch.xpack.esql.plugin.EsqlPlugin'
  extendedPlugins = ['x-pack-esql-core', 'lang-painless']
}

base {
  archivesName = 'x-pack-esql'
}

dependencies {
  compileOnly project(path: xpackModule('core'))
  compileOnly project(':modules:lang-painless:spi')
  compileOnly project(xpackModule('esql-core'))
  implementation project('compute')
  implementation project('compute:ann')
  implementation project(':libs:elasticsearch-dissect')
  implementation project(':libs:elasticsearch-grok')
  // Also contains a dummy processor to allow compilation with unused annotations.
  annotationProcessor project('compute:gen')

  testImplementation(project('qa:testFixtures')) {
    exclude(group:"org.elasticsearch.plugin", module: "esql")
  }
  testImplementation project(':test:framework')
  testImplementation(testArtifact(project(xpackModule('core'))))
  testImplementation project(path: xpackModule('enrich'))

  testImplementation project(path: ':modules:reindex')
  testImplementation project(path: ':modules:parent-join')
  testImplementation project(path: ':modules:analysis-common')
  testImplementation project(path: ':modules:ingest-common')
  testImplementation('net.nextencia:rrdiagram:0.9.4')
  testImplementation('org.webjars.npm:fontsource__roboto-mono:4.5.7')

  internalClusterTestImplementation project(":modules:mapper-extras")
}

tasks.named("compileJava").configure {
  options.compilerArgs.addAll(["-s", "src/main/generated"])
  // IntelliJ sticks generated files here and we can't stop it....
  exclude { it.file.toString().contains("src/main/generated-src/generated") }
}

interface Injected {
  @Inject FileSystemOperations getFs()
}

tasks.named("test").configure {
  if (BuildParams.isCi() == false) {
    systemProperty 'generateDocs', true
    def injected = project.objects.newInstance(Injected)
    doFirst {
      injected.fs.delete {
        it.delete("build/testrun/test/temp/esql/functions")
      }
    }
    File functionsFolder = file("build/testrun/test/temp/esql/functions")
    File signatureFolder = file("build/testrun/test/temp/esql/functions/signature")
    File typesFolder = file("build/testrun/test/temp/esql/functions/types")
    def functionsDocFolder = file("${rootDir}/docs/reference/esql/functions")
    def effectiveProjectDir = projectDir

    doLast {
      List types = typesFolder.list().findAll {it.endsWith("asciidoc")}
      int count = types == null ? 0 : types.size()
      Closure readExample = line -> {
        line.replaceAll(/read-example::([^\[]+)\[tag=([^,\]]+)(, ?json)?\]/, {
          String file = it[1]
          String tag = it[2]
          boolean isJson = it[3]
          String allExamples = new File("${effectiveProjectDir}/qa/testFixtures/src/main/resources/${file}").text
            .replaceAll(System.lineSeparator(), "\n")
          int start = allExamples.indexOf("tag::${tag}[]")
          int end = allExamples.indexOf("end::${tag}[]", start)
          if (start < 0 || end < 0) {
              throw new IllegalAccessException("can't find example ${file}::${tag}")
          }
          // Slice out the newlines
          start = allExamples.indexOf('\n', start) + 1
          end = allExamples.lastIndexOf('\n', end)
          String example = allExamples.substring(start, end)
          if (isJson) {
            example = example.replace("\"", "\\\"").replace("\n", "\\n")
          }
          return example;
        })
      }
      if (count == 0) {
        logger.quiet("ESQL Docs: No function signatures created. Skipping sync.")
      } else if (count == 1) {
        logger.quiet("ESQL Docs: Only files related to $types, patching them into place")
        injected.fs.sync {
          from functionsFolder
          into functionsDocFolder
          include '**/*.asciidoc', '**/*.svg', '**/*.md', '**/*.json'
          preserve {
            include '/*.asciidoc', '**/*.asciidoc', '**/*.md', '**/*.json', '**/*.svg', 'README.md'
          }
          filter readExample
        }
      } else {
        injected.fs.sync {
          from functionsFolder
          into functionsDocFolder
          include '**/*.asciidoc', '**/*.svg', '**/*.md', '**/*.json'
          preserve {
            include '/*.asciidoc', 'README.md'
          }
          filter readExample
        }
      }
    }
  }
}

/****************************************************************
 *  Enable QA/rest integration tests for snapshot builds only   *
 *  TODO: Enable for all builds upon this feature release       *
 ****************************************************************/
if (BuildParams.isSnapshotBuild()) {
  addQaCheckDependencies(project)
}

/**********************************************
 *          ESQL Parser regeneration           *
 **********************************************/

configurations {
  regenerate
}

dependencies {
  regenerate "org.antlr:antlr4:${versions.antlr4}"
}

String grammarPath = 'src/main/antlr'
String outputPath = 'src/main/java/org/elasticsearch/xpack/esql/parser'

pluginManager.withPlugin('com.diffplug.spotless') {
  spotless {
    java {
      // for some reason "${outputPath}/EsqlBaseParser*.java" does not match the same files...
      targetExclude "src/main/java/org/elasticsearch/xpack/esql/parser/EsqlBaseLexer*.java",
        "src/main/java/org/elasticsearch/xpack/esql/parser/EsqlBaseParser*.java",
        "src/main/generated/**/*.java",
        "src/main/generated-src/generated/**/*.java"
    }
  }
}

tasks.register("cleanGenerated", Delete) {
  delete fileTree(grammarPath) {
    include '*.tokens'
  }
  delete fileTree(outputPath) {
    include 'EsqlBase*.java'
  }
}

tasks.register("regenLexer", JavaExec) {
  dependsOn "cleanGenerated"
  mainClass = 'org.antlr.v4.Tool'
  classpath = configurations.regenerate
  systemProperty 'file.encoding', 'UTF-8'
  systemProperty 'user.language', 'en'
  systemProperty 'user.country', 'US'
  systemProperty 'user.variant', ''
  args '-Werror',
    '-package', 'org.elasticsearch.xpack.esql.parser',
    '-listener',
    '-visitor',
    '-o', outputPath,
    "${file(grammarPath)}/EsqlBaseLexer.g4"
}

tasks.register("regenParser", JavaExec) {
  dependsOn "cleanGenerated"
  dependsOn "regenLexer"
  mainClass = 'org.antlr.v4.Tool'
  classpath = configurations.regenerate
  systemProperty 'file.encoding', 'UTF-8'
  systemProperty 'user.language', 'en'
  systemProperty 'user.country', 'US'
  systemProperty 'user.variant', ''
  args '-Werror',
    '-package', 'org.elasticsearch.xpack.esql.parser',
    '-listener',
    '-visitor',
    '-o', outputPath,
    '-lib', outputPath,
    "${file(grammarPath)}/EsqlBaseParser.g4"
}

tasks.register("regen") {
  dependsOn "regenParser"
  doLast {
    // moves token files to grammar directory for use with IDE's
    ant.move(file: "${outputPath}/EsqlBaseLexer.tokens", toDir: grammarPath)
    ant.move(file: "${outputPath}/EsqlBaseParser.tokens", toDir: grammarPath)
    // make the generated classes package private
    ant.replaceregexp(
      match: 'public ((interface|class) \\QEsqlBase(Parser|Lexer)\\E\\w+)',
      replace: '\\1',
      encoding: 'UTF-8'
    ) {
      fileset(dir: outputPath, includes: 'EsqlBase*.java')
    }
    // nuke timestamps/filenames in generated files
    ant.replaceregexp(
      match: '\\Q// Generated from \\E.*',
      replace: '\\/\\/ ANTLR GENERATED CODE: DO NOT EDIT',
      encoding: 'UTF-8'
    ) {
      fileset(dir: outputPath, includes: 'EsqlBase*.java')
    }
    // remove tabs in antlr generated files
    ant.replaceregexp(match: '\t', flags: 'g', replace: '  ', encoding: 'UTF-8') {
      fileset(dir: outputPath, includes: 'EsqlBase*.java')
    }
    // suppress this-escape warnings on EsqlBaseLexer
    ant.replaceregexp(
      match: 'public EsqlBaseLexer',
      replace: '@SuppressWarnings("this-escape")${line.separator}  public EsqlBaseLexer',
      encoding: 'UTF-8'
    ) {
      fileset(dir: outputPath, includes: 'EsqlBaseLexer.java')
    }
    // suppress this-escape warnings on all internal EsqlBaseParser class constructores
    ant.replaceregexp(
      match: '([ ]+)public ([A-Z][a-z]+[a-z,A-Z]+\\()',
      flags: 'g',
      replace: '\\1@SuppressWarnings("this-escape")${line.separator}\\1public \\2',
      encoding: 'UTF-8'
    ) {
      fileset(dir: outputPath, includes: 'EsqlBaseParser.java')
    }
    // fix line endings
    ant.fixcrlf(srcdir: outputPath, eol: 'lf') {
      patternset(includes: 'EsqlBase*.java')
    }
  }
}

tasks.named("spotlessJava") { dependsOn stringTemplates }
tasks.named('checkstyleMain').configure {
  excludes = [ "**/*.java.st" ]
  exclude { it.file.toString().startsWith("${projectDir}/src/main/generated-src/generated") }
  exclude { it.file.toString().startsWith("${projectDir}/src/main/generated") }
}

def prop(Type, type, TYPE, BYTES, Array) {
  return [
    "Type" : Type,
    "type" : type,
    "TYPE" : TYPE,
    "BYTES" : BYTES,
    "Array" : Array,

    "int" : type == "int" ? "true" : "",
    "long" : type == "long" ? "true" : "",
    "double" : type == "double" ? "true" : "",
    "BytesRef" : type == "BytesRef" ? "true" : "",
    "boolean" : type == "boolean" ? "true" : "",
  ]
}

tasks.named('stringTemplates').configure {
  var intProperties = prop("Int", "int", "INT", "Integer.BYTES", "IntArray")
  var longProperties = prop("Long", "long", "LONG", "Long.BYTES", "LongArray")
  var doubleProperties = prop("Double", "double", "DOUBLE", "Double.BYTES", "DoubleArray")
  var bytesRefProperties = prop("BytesRef", "BytesRef", "BYTES_REF", "org.apache.lucene.util.RamUsageEstimator.NUM_BYTES_OBJECT_REF", "")
  var booleanProperties = prop("Boolean", "boolean", "BOOLEAN", "Byte.BYTES", "BitArray")
  // enrich
  File enrichResultBuilderInput = file("src/main/java/org/elasticsearch/xpack/esql/enrich/X-EnrichResultBuilder.java.st")
  template {
    it.properties = intProperties
    it.inputFile = enrichResultBuilderInput
    it.outputFile = "org/elasticsearch/xpack/esql/enrich/EnrichResultBuilderForInt.java"
  }
  template {
    it.properties = longProperties
    it.inputFile = enrichResultBuilderInput
    it.outputFile = "org/elasticsearch/xpack/esql/enrich/EnrichResultBuilderForLong.java"
  }
  template {
    it.properties = doubleProperties
    it.inputFile = enrichResultBuilderInput
    it.outputFile = "org/elasticsearch/xpack/esql/enrich/EnrichResultBuilderForDouble.java"
  }
  template {
    it.properties = bytesRefProperties
    it.inputFile = enrichResultBuilderInput
    it.outputFile = "org/elasticsearch/xpack/esql/enrich/EnrichResultBuilderForBytesRef.java"
  }
  template {
    it.properties = booleanProperties
    it.inputFile = enrichResultBuilderInput
    it.outputFile = "org/elasticsearch/xpack/esql/enrich/EnrichResultBuilderForBoolean.java"
  }
}

tasks.withType(CheckForbiddenApisTask).configureEach {
  signaturesFiles += files('src/main/resources/forbidden/ql-signatures.txt')
}

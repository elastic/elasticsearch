/*
 * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
 * or more contributor license agreements. Licensed under the Elastic License
 * 2.0; you may not use this file except in compliance with the Elastic License
 * 2.0.
 */

package org.elasticsearch.xpack.esql.approximate;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.elasticsearch.action.ActionListener;
import org.elasticsearch.compute.data.LongBlock;
import org.elasticsearch.xpack.esql.VerificationException;
import org.elasticsearch.xpack.esql.common.Failure;
import org.elasticsearch.xpack.esql.core.expression.Alias;
import org.elasticsearch.xpack.esql.core.expression.Attribute;
import org.elasticsearch.xpack.esql.core.expression.Expression;
import org.elasticsearch.xpack.esql.core.expression.Literal;
import org.elasticsearch.xpack.esql.core.expression.NameId;
import org.elasticsearch.xpack.esql.core.expression.NamedExpression;
import org.elasticsearch.xpack.esql.core.tree.Source;
import org.elasticsearch.xpack.esql.core.util.Holder;
import org.elasticsearch.xpack.esql.expression.function.aggregate.AggregateFunction;
import org.elasticsearch.xpack.esql.expression.function.aggregate.Avg;
import org.elasticsearch.xpack.esql.expression.function.aggregate.Count;
import org.elasticsearch.xpack.esql.expression.function.aggregate.Median;
import org.elasticsearch.xpack.esql.expression.function.aggregate.MedianAbsoluteDeviation;
import org.elasticsearch.xpack.esql.expression.function.aggregate.Percentile;
import org.elasticsearch.xpack.esql.expression.function.aggregate.StdDev;
import org.elasticsearch.xpack.esql.expression.function.aggregate.Sum;
import org.elasticsearch.xpack.esql.expression.function.aggregate.WeightedAvg;
import org.elasticsearch.xpack.esql.expression.function.scalar.convert.ToLong;
import org.elasticsearch.xpack.esql.expression.function.scalar.multivalue.ConfidenceInterval;
import org.elasticsearch.xpack.esql.expression.function.scalar.multivalue.MvAppend;
import org.elasticsearch.xpack.esql.expression.function.scalar.multivalue.MvContains;
import org.elasticsearch.xpack.esql.expression.function.scalar.random.Random;
import org.elasticsearch.xpack.esql.expression.predicate.logical.And;
import org.elasticsearch.xpack.esql.expression.predicate.nulls.IsNotNull;
import org.elasticsearch.xpack.esql.expression.predicate.operator.arithmetic.Div;
import org.elasticsearch.xpack.esql.expression.predicate.operator.comparison.NotEquals;
import org.elasticsearch.xpack.esql.plan.logical.Aggregate;
import org.elasticsearch.xpack.esql.plan.logical.ChangePoint;
import org.elasticsearch.xpack.esql.plan.logical.Dissect;
import org.elasticsearch.xpack.esql.plan.logical.Drop;
import org.elasticsearch.xpack.esql.plan.logical.Enrich;
import org.elasticsearch.xpack.esql.plan.logical.Eval;
import org.elasticsearch.xpack.esql.plan.logical.Filter;
import org.elasticsearch.xpack.esql.plan.logical.Grok;
import org.elasticsearch.xpack.esql.plan.logical.Insist;
import org.elasticsearch.xpack.esql.plan.logical.Keep;
import org.elasticsearch.xpack.esql.plan.logical.LeafPlan;
import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;
import org.elasticsearch.xpack.esql.plan.logical.OrderBy;
import org.elasticsearch.xpack.esql.plan.logical.Project;
import org.elasticsearch.xpack.esql.plan.logical.Rename;
import org.elasticsearch.xpack.esql.plan.logical.Sample;
import org.elasticsearch.xpack.esql.plan.logical.UnaryPlan;
import org.elasticsearch.xpack.esql.plan.logical.local.EsqlProject;
import org.elasticsearch.xpack.esql.session.Result;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.Set;
import java.util.stream.Collectors;

/**
 * This class computes approximate and fast results for certain classes of
 * ES|QL queries.
 * <p>
 * A query is suitable for approximation if it contains at least one
 * {@code STATS} command, and all commands between the source and the leftmost
 * {@code STATS} command can be swapped with {@code SAMPLE}. A command can be
 * swapped with {@code SAMPLE} if it is either mapping one row to one row (e.g.
 * {@code EVAL} or {@code GROK}), or if it is filtering rows (e.g. {@code FILTER}
 * or {@code SAMPLE}). This is verified by {@link Approximate#verifyPlan}.
 * <p>
 * If this is the case, the {@code STATS} can be replaced by {@code SAMPLE} and
 * a {@code STATS} with sample correction terms, and the {@code SAMPLE} can be
 * moved to the source and executed inside Lucene. This new logical plan is
 * generated by {@link Approximate#approximatePlan}.
 * <p>
 * To compute the appropriate sample probability, first a target number of rows
 * is set. For now this is a fixed number ({@link Approximate#SAMPLE_ROW_COUNT}).
 * <p>
 * Next, the total number of rows in the source index is counted via the plan
 * {@link Approximate#sourceCountPlan}. This plan should execute fast. When
 * there are no filter commands, the sample probability can be directly
 * computed as a ratio of the target number of rows and this total number.
 * <p>
 * In the presence of filters commands, another step is needed. The initial
 * sample probability is set to the ratio above and the number of rows is
 * sampled with the plan {@link Approximate#countPlan}. As long as the sampled
 * number of rows is smaller than intended, the probability is scaled up until
 * a good probability is reached. This final probability is then used for
 * approximating the original plan.
 */
public class Approximate {

    public interface LogicalPlanRunner {
        void run(LogicalPlan plan, ActionListener<Result> listener);
    }

    /**
     * These commands preserve all rows, making it easy to predict the number of output rows.
     */
    private static final Set<Class<? extends LogicalPlan>> ROW_PRESERVING_COMMANDS = Set.of(
        ChangePoint.class,
        Dissect.class,
        Drop.class,
        Enrich.class,
        EsqlProject.class,
        Eval.class,
        Grok.class,
        Insist.class,
        Keep.class,
        OrderBy.class,
        Project.class,
        Rename.class
    );

    private static final Set<Class<? extends AggregateFunction>> SUPPORTED_SINGLE_VALUED_AGGS = Set.of(
        Avg.class,
        Count.class,
        Median.class,
        MedianAbsoluteDeviation.class,
        Percentile.class,
        StdDev.class,
        Sum.class,
        WeightedAvg.class
    );

    private static final Set<Class<? extends AggregateFunction>> SAMPLE_CORRECTED_AGGS = Set.of(
        Count.class,
        Sum.class
    );

    private static final Set<Class<? extends AggregateFunction>> SUPPORTED_MULTI_VALUED_AGGS = Set.of(
        org.elasticsearch.xpack.esql.expression.function.aggregate.Sample.class
    );

    // TODO: find a good default value, or alternative ways of setting it
    private static final int SAMPLE_ROW_COUNT = 100000;

    private static final int BUCKET_COUNT = 16;

    private static final Logger logger = LogManager.getLogger(Approximate.class);

    private final LogicalPlan logicalPlan;
    private final boolean hasFilters;

    public Approximate(LogicalPlan logicalPlan) {
        this.logicalPlan = logicalPlan;
        this.hasFilters = verifyPlan();
    }

    /**
     * Computes approximate results for the logical plan.
     */
    public void approximate(LogicalPlanRunner runner, ActionListener<Result> listener) {
        runner.run(sourceCountPlan(), sourceCountListener(runner, listener));
    }

    /**
     * Verifies that a plan is suitable for approximation.
     *
     * @return whether the plan contains filters commands
     */
    private boolean verifyPlan() {
        if (logicalPlan.preOptimized() == false) {
            throw new IllegalStateException("Expected pre-optimized plan");
        }
        if (logicalPlan.anyMatch(plan -> plan instanceof Aggregate) == false) {
            throw new VerificationException(
                List.of(Failure.fail(logicalPlan.collectLeaves().getFirst(), "query without [STATS] cannot be approximated"))
            );
        }
        // For now, only support unary plans.
        // TODO: support binary plans (e.g. join) and n-ary plans (e.g. fork).
        logicalPlan.forEachUp(plan -> {
            if (plan instanceof LeafPlan == false && plan instanceof UnaryPlan == false) {
                throw new VerificationException(
                    List.of(Failure.fail(plan, "query with [" + plan.nodeName().toUpperCase(Locale.ROOT) + "] cannot be approximated"))
                );
            }
        });

        Holder<Boolean> encounteredStats = new Holder<>(false);
        Holder<Boolean> hasFilters = new Holder<>(false);
        logicalPlan.transformUp(plan -> {
            if (encounteredStats.get() == false) {
                if (plan instanceof Aggregate) {
                    encounteredStats.set(true);
                    plan.transformExpressionsOnly(AggregateFunction.class, aggFn -> {
                        if (SUPPORTED_SINGLE_VALUED_AGGS.contains(aggFn.getClass()) == false && SUPPORTED_MULTI_VALUED_AGGS.contains(aggFn.getClass()) == false) {
                            throw new VerificationException(
                                List.of(Failure.fail(aggFn, "aggregation function [" + aggFn.nodeName().toUpperCase() + "] cannot be approximated"))
                            );
                        }
                        return aggFn;
                    });
                } else if (ROW_PRESERVING_COMMANDS.contains(plan.getClass()) == false) {
                    hasFilters.set(true);
                }
            } else {
                if (plan instanceof Aggregate) {
                    throw new VerificationException(
                        List.of(Failure.fail(plan, "query with multiple chained [STATS] cannot be approximated"))
                    );
                }
            }
            return plan;
        });

        return hasFilters.get();
    }

    /**
     * Plan that counts the number of rows in the source index.
     * This is the ES|QL query {@code FROM index | STATS COUNT(*)}.
     */
    private LogicalPlan sourceCountPlan() {
        LogicalPlan sourceCountPlan = logicalPlan.transformUp(plan -> {
            if (plan instanceof LeafPlan) {
                plan = new Aggregate(
                    Source.EMPTY,
                    plan,
                    List.of(),
                    List.of(new Alias(Source.EMPTY, ".approximate-count", new Count(Source.EMPTY, Literal.keyword(Source.EMPTY, "*"))))
                );
            } else {
                plan = plan.children().getFirst();
            }
            return plan;
        });

        sourceCountPlan.setPreOptimized();
        return sourceCountPlan;
    }

    /**
     * Receives the total number of rows, and runs either the
     * {@link Approximate#approximatePlan} or {@link Approximate#countPlan}
     * depending on whether filter commands are present.
     */
    private ActionListener<Result> sourceCountListener(LogicalPlanRunner runner, ActionListener<Result> listener) {
        return listener.delegateFailureAndWrap((countListener, countResult) -> {
            logger.debug("sourceCountPlan result: {} rows", rowCount(countResult));
            double sampleProbability = sampleProbability(countResult);
            countResult.pages().getFirst().close();
            if (hasFilters == false || sampleProbability == 1.0) {
                runner.run(approximatePlan(sampleProbability), listener);
            } else {
                runner.run(countPlan(sampleProbability), countListener(runner, sampleProbability, listener));
            }
        });
    }

    /**
     * Plan that counts the number of rows reaching the leftmost STATS function.
     * This is number is approximated to speed up the query execution.
     * This is the ES|QL query {@code FROM index | (...) | SAMPLE p | STATS COUNT(*) / p}.
     */
    private LogicalPlan countPlan(double sampleProbability) {
        Holder<Boolean> encounteredStats = new Holder<>(false);
        LogicalPlan countPlan = logicalPlan.transformUp(plan -> {
            if (plan instanceof LeafPlan) {
                encounteredStats.set(false);
            } else if (encounteredStats.get() == false) {
                if (plan instanceof Aggregate aggregate) {
                    encounteredStats.set(true);
                    Sample sample = new Sample(Source.EMPTY, Literal.fromDouble(Source.EMPTY, sampleProbability), aggregate.child());
                    plan = new Aggregate(
                        Source.EMPTY,
                        sample,
                        List.of(),
                        List.of(new Alias(Source.EMPTY, ".approximate-count", new Count(Source.EMPTY, Literal.keyword(Source.EMPTY, "*"))))
                    );
                }
            } else {
                plan = plan.children().getFirst();
            }
            return plan;
        });

        countPlan.setPreOptimized();
        return countPlan;
    }

    /**
     * Receives the sampled number of rows reaching the leftmost STATS function.
     * Runs either the {@link Approximate#approximatePlan} or a next iteration
     * {@link Approximate#countPlan} depending on whether the current count is
     * sufficient.
     */
    private ActionListener<Result> countListener(LogicalPlanRunner runner, double probability, ActionListener<Result> listener) {
        return listener.delegateFailureAndWrap((countListener, countResult) -> {
            long rowCount = rowCount(countResult);
            logger.debug("countPlan result (p={}): {} rows", probability, rowCount);
            double newProbability = probability * SAMPLE_ROW_COUNT / Math.max(1, rowCount);
            countResult.pages().getFirst().close();
            if (rowCount <= SAMPLE_ROW_COUNT / 2 && newProbability < 1.0) {
                runner.run(countPlan(newProbability), countListener(runner, newProbability, listener));
            } else {
                runner.run(approximatePlan(newProbability), listener);
            }
        });
    }

    /**
     * Returns a sample probability based on the total number of rows.
     */
    private double sampleProbability(Result countResult) {
        long rowCount = rowCount(countResult);
        return rowCount <= SAMPLE_ROW_COUNT ? 1.0 : (double) SAMPLE_ROW_COUNT / rowCount;
    }

    /**
     * Returns the row count in the result.
     */
    private long rowCount(Result countResult) {
        return ((LongBlock) (countResult.pages().getFirst().getBlock(0))).getLong(0);
    }

    /**
     * Returns a plan that approximates the original plan. It consists of the
     * original plan, with the leftmost STATS function replaced by:
     * "SAMPLE probability | STATS sample_corrected_aggs".
     */
    private LogicalPlan approximatePlan(double sampleProbability) {
        if (sampleProbability >= 1.0) {
            logger.debug("using original plan (too few rows)");
            return logicalPlan;
        }

        logger.debug("generating approximate plan (p={})", sampleProbability);
        Holder<Boolean> encounteredStats = new Holder<>(false);
        Map<NameId, List<Alias>> variablesWithConfidenceInterval = new HashMap<>();

        Alias bucketIdField = new Alias(
            Source.EMPTY,
            "$bucket_id",
            new MvAppend(
                Source.EMPTY,
                Literal.integer(Source.EMPTY, -1),
                new Random(Source.EMPTY, Literal.integer(Source.EMPTY, BUCKET_COUNT))
            )
        );

        LogicalPlan approximatePlan = logicalPlan.transformUp(plan -> {
            if (plan instanceof LeafPlan) {
                plan = new Sample(Source.EMPTY, Literal.fromDouble(Source.EMPTY, sampleProbability), plan);
            } else if (encounteredStats.get() == false && plan instanceof Aggregate aggregate) {
                encounteredStats.set(true);

                Eval addBucketId = new Eval(Source.EMPTY, aggregate.child(), List.of(bucketIdField));
                List<NamedExpression> aggregates = new ArrayList<>();
                Expression allBucketsNonEmpty = Literal.TRUE;
                for (NamedExpression aggOrKey : aggregate.aggregates()) {
                    if ((aggOrKey instanceof Alias alias && alias.child() instanceof AggregateFunction) == false) {
                        // This is a grouping key, not an aggregate function.
                        aggregates.add(aggOrKey);
                        continue;
                    }
                    Alias aggAlias = (Alias) aggOrKey;
                    AggregateFunction agg = (AggregateFunction) aggAlias.child();
                    boolean isMultiValued = SUPPORTED_MULTI_VALUED_AGGS.contains(agg.getClass());
                    int bucketCount = isMultiValued ? 0 : BUCKET_COUNT;
                    List<Alias> bucketedAggs = new ArrayList<>();
                    for (int bucketId = -1; bucketId < bucketCount; bucketId++) {
                        AggregateFunction bucketedAgg = agg.withFilter(
                            new MvContains(Source.EMPTY, bucketIdField.toAttribute(), Literal.integer(Source.EMPTY, bucketId)));
                        Expression correctedAgg = correctForSampling(bucketedAgg, bucketId == -1 ? sampleProbability : sampleProbability / BUCKET_COUNT);
                        Alias correctedAggAlias = bucketId == -1
                            ? aggAlias.replaceChild(correctedAgg)
                            : new Alias(
                                Source.EMPTY,
                                aggOrKey.name() + "$bucket:" + bucketId,
                                correctedAgg
                            );
                        aggregates.add(correctedAggAlias);
                        if (bucketId >= 0) {
                            bucketedAggs.add(correctedAggAlias);
                        }
                        allBucketsNonEmpty = new And(Source.EMPTY, allBucketsNonEmpty,
                            agg instanceof Count
                                ? new NotEquals(Source.EMPTY, correctedAggAlias.toAttribute(), Literal.integer(Source.EMPTY, 0))
                                : new IsNotNull(Source.EMPTY, correctedAggAlias.toAttribute()));
                    }
                    if (isMultiValued == false) {
                        variablesWithConfidenceInterval.put(aggOrKey.id(), bucketedAggs);
                    }
                }
                plan = aggregate.with(addBucketId, aggregate.groupings(), aggregates);
                plan = new Filter(Source.EMPTY, plan, allBucketsNonEmpty);

            } else if (encounteredStats.get()) {
                switch (plan) {
                    case Eval eval:
                        List<Alias> newFields = new ArrayList<>(eval.fields());
                        for (Alias field : eval.fields()) {
                            if (field.dataType().isNumeric() == false || field.child().anyMatch(expr -> expr instanceof MvAppend)) {
                                continue;
                            }
                            if (field.child().anyMatch(expr -> expr instanceof NamedExpression named && variablesWithConfidenceInterval.containsKey(named.id()))) {
                                List<Alias> newBuckets = new ArrayList<>();
                                for (int bucketId = 0; bucketId < BUCKET_COUNT; bucketId++) {
                                    final int finalBucketId = bucketId;
                                    Expression newChild = field.child().transformDown(expr -> {
                                        if (expr instanceof NamedExpression named && variablesWithConfidenceInterval.containsKey(named.id())) {
                                            List<Alias> buckets = variablesWithConfidenceInterval.get(named.id());
                                            return buckets.get(finalBucketId).toAttribute();
                                        } else {
                                            return expr;
                                        }
                                    });
                                    Alias newField = new Alias(
                                        Source.EMPTY,
                                        field.name() + "$bucket:" + bucketId,
                                        newChild
                                    );
                                    newBuckets.add(newField);
                                }
                                variablesWithConfidenceInterval.put(field.id(), newBuckets);
                                newFields.addAll(newBuckets);
                            }
                        }
                        plan = new Eval(Source.EMPTY, eval.child(), newFields);
                        break;
                    case Project project:
                        for (NamedExpression projection : project.projections()) {
                            if (projection instanceof Alias alias1 && alias1.child() instanceof NamedExpression named && variablesWithConfidenceInterval.containsKey(named.id())) {
                                variablesWithConfidenceInterval.put(alias1.id(), variablesWithConfidenceInterval.get(named.id()));
                            }
                        }
                        break;
                    default:
                }
            }
            return plan;
        });

        List<Alias> confidenceIntervals = new ArrayList<>();
        for (Attribute output : logicalPlan.output()) {
            if (variablesWithConfidenceInterval.containsKey(output.id())) {
                List<Alias> buckets = variablesWithConfidenceInterval.get(output.id());
                Expression appendedBuckets = buckets.getFirst().toAttribute();
                for (int i = 1; i < buckets.size(); i++) {
                    appendedBuckets = new MvAppend(Source.EMPTY, appendedBuckets, buckets.get(i).toAttribute());
                }
                confidenceIntervals.add(new Alias(
                    Source.EMPTY,
                    "CONFIDENCE_INTERVAL(" + output.name() + ")",
                    new ConfidenceInterval(
                        Source.EMPTY,
                        output,
                        appendedBuckets
                    )
                ));
            }
        }

        approximatePlan = new Eval(
            Source.EMPTY,
            approximatePlan,
            confidenceIntervals
        );

        Set<Attribute> dropAttributes = variablesWithConfidenceInterval.values().stream().flatMap(List::stream).map(Alias::toAttribute).collect(Collectors.toSet());
        List<Attribute> keepAttributes = new ArrayList<>(approximatePlan.output());
        keepAttributes.removeAll(dropAttributes);

        approximatePlan = new Project(
            Source.EMPTY,
            approximatePlan,
            keepAttributes
        );

        approximatePlan.setPreOptimized();

        logger.debug("approximate plan:\n{}", approximatePlan);

        return approximatePlan;
    }

    private static Expression correctForSampling(AggregateFunction agg, double sampleProbability) {
        if (SAMPLE_CORRECTED_AGGS.contains(agg.getClass()) == false) {
            return agg;
        }
        Expression correctedAgg = new Div(agg.source(), agg, Literal.fromDouble(Source.EMPTY, sampleProbability));
        return switch (agg.dataType()) {
            case DOUBLE -> correctedAgg;
            case LONG -> new ToLong(agg.source(), correctedAgg);
            default -> throw new IllegalStateException("unexpected data type [" + agg.dataType() + "]");
        };
    }
}

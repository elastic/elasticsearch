/*
 * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
 * or more contributor license agreements. Licensed under the Elastic License
 * 2.0; you may not use this file except in compliance with the Elastic License
 * 2.0.
 */

package org.elasticsearch.xpack.esql.approximate;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.elasticsearch.action.ActionListener;
import org.elasticsearch.compute.data.LongBlock;
import org.elasticsearch.xpack.esql.VerificationException;
import org.elasticsearch.xpack.esql.common.Failure;
import org.elasticsearch.xpack.esql.core.expression.Alias;
import org.elasticsearch.xpack.esql.core.expression.Expression;
import org.elasticsearch.xpack.esql.core.expression.Literal;
import org.elasticsearch.xpack.esql.core.expression.NamedExpression;
import org.elasticsearch.xpack.esql.core.tree.Source;
import org.elasticsearch.xpack.esql.core.type.DataType;
import org.elasticsearch.xpack.esql.core.util.Holder;
import org.elasticsearch.xpack.esql.expression.function.aggregate.AggregateFunction;
import org.elasticsearch.xpack.esql.expression.function.aggregate.Count;
import org.elasticsearch.xpack.esql.expression.function.aggregate.Min;
import org.elasticsearch.xpack.esql.expression.function.aggregate.Top;
import org.elasticsearch.xpack.esql.expression.function.scalar.conditional.Case;
import org.elasticsearch.xpack.esql.expression.function.scalar.multivalue.ConfidenceInterval;
import org.elasticsearch.xpack.esql.expression.function.scalar.multivalue.MvAppend;
import org.elasticsearch.xpack.esql.expression.function.scalar.random.Random;
import org.elasticsearch.xpack.esql.expression.predicate.operator.comparison.Equals;
import org.elasticsearch.xpack.esql.expression.predicate.operator.comparison.NotEquals;
import org.elasticsearch.xpack.esql.plan.logical.Aggregate;
import org.elasticsearch.xpack.esql.plan.logical.ChangePoint;
import org.elasticsearch.xpack.esql.plan.logical.Dissect;
import org.elasticsearch.xpack.esql.plan.logical.Drop;
import org.elasticsearch.xpack.esql.plan.logical.Enrich;
import org.elasticsearch.xpack.esql.plan.logical.Eval;
import org.elasticsearch.xpack.esql.plan.logical.Grok;
import org.elasticsearch.xpack.esql.plan.logical.Insist;
import org.elasticsearch.xpack.esql.plan.logical.Keep;
import org.elasticsearch.xpack.esql.plan.logical.LeafPlan;
import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;
import org.elasticsearch.xpack.esql.plan.logical.OrderBy;
import org.elasticsearch.xpack.esql.plan.logical.Project;
import org.elasticsearch.xpack.esql.plan.logical.Rename;
import org.elasticsearch.xpack.esql.plan.logical.Sample;
import org.elasticsearch.xpack.esql.plan.logical.UnaryPlan;
import org.elasticsearch.xpack.esql.plan.logical.local.EsqlProject;
import org.elasticsearch.xpack.esql.session.Result;

import java.util.ArrayList;
import java.util.List;
import java.util.Set;

/**
 * This class computes approximate and fast results for certain classes of
 * ES|QL queries.
 * <p>
 * A query is suitable for approximation if it contains at least one
 * {@code STATS} command, and all commands between the source and the leftmost
 * {@code STATS} command can be swapped with {@code SAMPLE}. A command can be
 * swapped with {@code SAMPLE} if it is either mapping one row to one row (e.g.
 * {@code EVAL} or {@code GROK}), or if it is filtering rows (e.g. {@code FILTER}
 * or {@code SAMPLE}). This is verified by {@link Approximate#verifyPlan}.
 * <p>
 * If this is the case, the {@code STATS} can be replaced by {@code SAMPLE} and
 * a {@code STATS} with sample correction terms, and the {@code SAMPLE} can be
 * moved to the source and executed inside Lucene. This new logical plan is
 * generated by {@link Approximate#approximatePlan}.
 * <p>
 * To compute the appropriate sample probability, first a target number of rows
 * is set. For now this is a fixed number ({@link Approximate#SAMPLE_ROW_COUNT}).
 * <p>
 * Next, the total number of rows in the source index is counted via the plan
 * {@link Approximate#sourceCountPlan}. This plan should execute fast. When
 * there are no filter commands, the sample probability can be directly
 * computed as a ratio of the target number of rows and this total number.
 * <p>
 * In the presence of filters commands, another step is needed. The initial
 * sample probability is set to the ratio above and the number of rows is
 * sampled with the plan {@link Approximate#countPlan}. As long as the sampled
 * number of rows is smaller than intended, the probability is scaled up until
 * a good probability is reached. This final probability is then used for
 * approximating the original plan.
 */
public class Approximate {

    public interface LogicalPlanRunner {
        void run(LogicalPlan plan, ActionListener<Result> listener);
    }


    /**
     * These commands preserve all rows, making it easy to predict the number of output rows.
     */
    private static final Set<Class<? extends LogicalPlan>> ROW_PRESERVING_COMMANDS = Set.of(
        ChangePoint.class,
        Dissect.class,
        Drop.class,
        Enrich.class,
        EsqlProject.class,
        Eval.class,
        Grok.class,
        Insist.class,
        Keep.class,
        OrderBy.class,
        Project.class,
        Rename.class
    );

    // TODO: find a good default value, or alternative ways of setting it
    private static final int SAMPLE_ROW_COUNT = 100000;

    private static final int BUCKET_COUNT = 25;

    private static final Logger logger = LogManager.getLogger(Approximate.class);

    private final LogicalPlan logicalPlan;
    private final boolean hasFilters;

    public Approximate(LogicalPlan logicalPlan) {
        this.logicalPlan = logicalPlan;
        this.hasFilters = verifyPlan();
    }

    /**
     * Computes approximate results for the logical plan.
     */
    public void approximate(LogicalPlanRunner runner, ActionListener<Result> listener) {
        runner.run(sourceCountPlan(), sourceCountListener(runner, listener));
    }

    /**
     * Verifies that a plan is suitable for approximation.
     *
     * @return whether the plan contains filters commands
     */
    private boolean verifyPlan() {
        if (logicalPlan.preOptimized() == false) {
            throw new IllegalStateException("Expected pre-optimized plan");
        }
        if (logicalPlan.anyMatch(plan -> plan instanceof Aggregate) == false) {
            throw new VerificationException(
                List.of(Failure.fail(logicalPlan.collectLeaves().getFirst(), "query without [STATS] cannot be approximated"))
            );
        }
        // For now, only support unary plans.
        // TODO: support binary plans (e.g. join) and n-ary plans (e.g. fork).
        logicalPlan.forEachUp(plan -> {
            if (plan instanceof LeafPlan == false && plan instanceof UnaryPlan == false) {
                throw new VerificationException(
                    List.of(Failure.fail(plan, "query with [" + plan.nodeName() + "] cannot be approximated"))
                );
            }
        });

        Holder<Boolean> encounteredStats = new Holder<>(false);
        Holder<Boolean> hasFilters = new Holder<>(false);
        logicalPlan.transformUp(plan -> {
            if (encounteredStats.get() == false) {
                if (plan instanceof Aggregate) {
                    encounteredStats.set(true);
                } else if (ROW_PRESERVING_COMMANDS.contains(plan.getClass()) == false) {
                    hasFilters.set(true);
                }
            }
            return plan;
        });

        return hasFilters.get();
    }

    /**
     * Plan that counts the number of rows in the source index.
     * This is the ES|QL query {@code FROM index | STATS COUNT(*)}.
     */
    private LogicalPlan sourceCountPlan() {
        LogicalPlan sourceCountPlan = logicalPlan.transformUp(plan -> {
            if (plan instanceof LeafPlan) {
                plan = new Aggregate(
                    Source.EMPTY,
                    plan,
                    List.of(),
                    List.of(new Alias(Source.EMPTY, ".approximate-count", new Count(Source.EMPTY, Literal.keyword(Source.EMPTY, "*"))))
                );
            } else {
                plan = plan.children().getFirst();
            }
            return plan;
        });

        sourceCountPlan.setPreOptimized();
        return sourceCountPlan;
    }

    /**
     * Receives the total number of rows, and runs either the
     * {@link Approximate#approximatePlan} or {@link Approximate#countPlan}
     * depending on whether filter commands are present.
     */
    private ActionListener<Result> sourceCountListener(LogicalPlanRunner runner, ActionListener<Result> listener) {
        return listener.delegateFailureAndWrap((countListener, countResult) -> {
            logger.debug("sourceCountPlan result: {} rows", rowCount(countResult));
            double sampleProbability = sampleProbability(countResult);
            countResult.pages().getFirst().close();
            if (hasFilters == false || sampleProbability == 1.0) {
                runner.run(approximatePlan(sampleProbability), listener);
            } else {
                runner.run(countPlan(sampleProbability), countListener(runner, sampleProbability, listener));
            }
        });
    }

    /**
     * Plan that counts the number of rows reaching the leftmost STATS function.
     * This is number is approximated to speed up the query execution.
     * This is the ES|QL query {@code FROM index | (...) | SAMPLE p | STATS COUNT(*) / p}.
     */
    private LogicalPlan countPlan(double sampleProbability) {
        Holder<Boolean> encounteredStats = new Holder<>(false);
        LogicalPlan countPlan = logicalPlan.transformUp(plan -> {
            if (plan instanceof LeafPlan) {
                encounteredStats.set(false);
            } else if (encounteredStats.get() == false) {
                if (plan instanceof Aggregate aggregate) {
                    encounteredStats.set(true);
                    Sample sample = new Sample(Source.EMPTY, Literal.fromDouble(Source.EMPTY, sampleProbability), aggregate.child());
                    plan = new Aggregate(
                        Source.EMPTY,
                        sample,
                        List.of(),
                        List.of(new Alias(Source.EMPTY, ".approximate-count", new Count(Source.EMPTY, Literal.keyword(Source.EMPTY, "*"))))
                    );
                }
            } else {
                plan = plan.children().getFirst();
            }
            return plan;
        });

        countPlan.setPreOptimized();
        return countPlan;
    }

    /**
     * Receives the sampled number of rows reaching the leftmost STATS function.
     * Runs either the {@link Approximate#approximatePlan} or a next iteration
     * {@link Approximate#countPlan} depending on whether the current count is
     * sufficient.
     */
    private ActionListener<Result> countListener(LogicalPlanRunner runner, double probability, ActionListener<Result> listener) {
        return listener.delegateFailureAndWrap((countListener, countResult) -> {
            long rowCount = rowCount(countResult);
            logger.debug("countPlan result (p={}): {} rows", probability, rowCount);
            double newProbability = probability * SAMPLE_ROW_COUNT / Math.max(1, rowCount);
            countResult.pages().getFirst().close();
            if (rowCount <= SAMPLE_ROW_COUNT / 2 && newProbability < 1.0) {
                runner.run(countPlan(newProbability), countListener(runner, newProbability, listener));
            } else {
                runner.run(approximatePlan(newProbability), listener);
            }
        });
    }

    /**
     * Returns a sample probability based on the total number of rows.
     */
    private double sampleProbability(Result countResult) {
        long rowCount = rowCount(countResult);
        return rowCount <= SAMPLE_ROW_COUNT ? 1.0 : (double) SAMPLE_ROW_COUNT / rowCount;
    }

    /**
     * Returns the row count in the result.
     */
    private long rowCount(Result countResult) {
        return ((LongBlock) (countResult.pages().getFirst().getBlock(0))).getLong(0);
    }

    /**
     * Returns a plan that approximates the original plan. It consists of the
     * original plan, with the leftmost STATS function replaced by:
     * "SAMPLE probability | STATS sample_corrected_aggs".
     */
    private LogicalPlan approximatePlan(double sampleProbability) {
        if (sampleProbability >= 1.0) {
            logger.debug("using original plan (too few rows)");
            return logicalPlan;
        }

        logger.info("### BEFORE APPROXIMATE:\n{}", logicalPlan);

        logger.debug("generating approximate plan (p={})", sampleProbability);
        Holder<Boolean> encounteredStats = new Holder<>(false);
        LogicalPlan approximatePlan = logicalPlan.transformUp(plan -> {
            if (plan instanceof LeafPlan) {
                return new Sample(Source.EMPTY, Literal.fromDouble(Source.EMPTY, sampleProbability), plan);
            } else if (encounteredStats.get() == false && plan instanceof Aggregate aggregate) {
                encounteredStats.set(true);
                Alias bucketId = new Alias(
                    Source.EMPTY,
                    ".bucket_id",
                    new MvAppend(
                        Source.EMPTY,
                        Literal.integer(Source.EMPTY, -1),
                        new Random(Source.EMPTY, Literal.integer(Source.EMPTY, BUCKET_COUNT))
                    )
                );
                Eval addBucketId = new Eval(Source.EMPTY, aggregate.child(), List.of(bucketId));
                List<NamedExpression> aggregates = new ArrayList<>();
                for (NamedExpression aggr : aggregate.aggregates()) {
                    if (aggr instanceof Alias alias && alias.child() instanceof AggregateFunction) {
                        aggregates.add(new Alias(Source.EMPTY, ".bucketed-" + alias.name(), alias.child()));
                    } else {
                        aggregates.add(aggr);
                    }
                }
                List<Expression> groupings = new ArrayList<>(aggregate.groupings());
                groupings.add(bucketId.toAttribute());
                aggregates.add(bucketId.toAttribute());
                Aggregate aggregateWithBucketId = (Aggregate) aggregate.with(addBucketId, groupings, aggregates)
                    .transformExpressionsOnlyUp(
                        expr -> expr instanceof NeedsSampleCorrection nsc ? nsc.sampleCorrection(
                            new Case(Source.EMPTY,
                                new Equals(Source.EMPTY, bucketId.toAttribute(), Literal.integer(Source.EMPTY, -1)),
                                List.of(
                                    Literal.fromDouble(Source.EMPTY, sampleProbability),
                                    Literal.fromDouble(Source.EMPTY, sampleProbability / BUCKET_COUNT)
                                )
                            )
                        ) : expr);
                aggregates = new ArrayList<>();
                for (int i = 0; i < aggregate.aggregates().size(); i++) {
                    NamedExpression aggr = aggregate.aggregates().get(i);
                    NamedExpression sampledAggr = aggregateWithBucketId.aggregates().get(i);
                    if (aggr instanceof Alias alias && alias.child() instanceof AggregateFunction aggFn) {
                        // TODO: probably filter low non-empty bucket counts. They're inaccurate and for skew, you need >=3.
                        aggregates.add(
                            alias.replaceChild(
                                new ConfidenceInterval( // TODO: move confidence level to the end
                                    Source.EMPTY,
                                    new Min(
                                        Source.EMPTY,
                                        sampledAggr.toAttribute(),
                                        new Equals(Source.EMPTY, bucketId.toAttribute(), Literal.integer(Source.EMPTY, -1))
                                    ),
                                    new Top(
                                        Source.EMPTY,
                                        sampledAggr.toAttribute(),
                                        new NotEquals(Source.EMPTY, bucketId.toAttribute(), Literal.integer(Source.EMPTY, -1)),
                                        Literal.integer(Source.EMPTY, BUCKET_COUNT),
                                        Literal.keyword(Source.EMPTY, "ASC")
                                    ),
                                    Literal.integer(Source.EMPTY, BUCKET_COUNT),
                                    Literal.fromDouble(Source.EMPTY, aggFn instanceof NeedsSampleCorrection ? 0.0 : Double.NaN)
                                )
                            )
                        );
                    } else {
                        aggregates.add(aggr);
                    }
                }
                plan = new Aggregate(
                    Source.EMPTY,
                    aggregateWithBucketId,
                    aggregate.groupings().stream().map(e -> e instanceof Alias a ? a.toAttribute() : e).toList(),
                    aggregates
                );
            }
            return plan;
        });

        logger.info("### AFTER APPROXIMATE:\n{}", approximatePlan);

        approximatePlan.setPreOptimized();
        return approximatePlan;
    }
}
